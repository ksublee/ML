{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층 신경망 훈련하기\n",
    "\n",
    "심층 신경망 훈련 도중 다음과 같은 상황을 마주할 수 있다.\n",
    "\n",
    "* 까다로운 그레디언트 소실 또는 그레디언트 폭주 문제에 직면할 수 있음. 심층 신경망 아래쪽으로 갈수록 그레디언트가 점점 작아지거나 커지는 현상\n",
    "\n",
    "* 대규모 신경망을 훈련하기 위한 데이터가 충분치 않거나 레이블을 만드는데 비용이 많이 듬\n",
    "\n",
    "* 훈련이 극단적으로 느려짐\n",
    "\n",
    "* 수백만개의 파라미터를 가진 모델은 과적합될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그레디언트 소실, 폭주 문제\n",
    "\n",
    "역전파 알고리즘이 하위층으로 진행될수록 그레디언트가 작아지거나 커지는 현상은 훈련을 어렵게 한다.\n",
    "\n",
    "의심되는 원인으로서 많이 사용되는 로지스틱 시그모이드 활성화 함수와, 표준정규분포 가중치 초기화 방법이 거론된다.\n",
    "\n",
    "로지스틱 함수는 입력인 양수나 음수로 커지면 기울기가 0에 매우 가까워진다.\n",
    "\n",
    "역전파가 될 때, 전달될 그레디언트가 거의 없고, 조금 있는 그레디언트는 최상위층으로부터 진행되며 점점 약해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가중치 초기화 방법\n",
    "\n",
    "로지스틱 함수를 이용할 때, 각 층의 연결 가중치를 아래의 식대로 무작위로 초기화하면 그레디언트 문제를 완화할 수 있다.\n",
    "\n",
    "이를 Xavier initialization라고 한다.\n",
    "\n",
    "$$ \\text{Normal distribution with mean 0 and sd } \\sigma = \\sqrt{\\frac{1}{fan_{\\mathrm{avg}}}} $$\n",
    "$$ \\text{ or a uniform distribution between } -r \\text{ and } r, \\text{ with } r = \\sqrt{\\frac{3}{fan_{\\mathrm{avg}}}} $$\n",
    "\n",
    "여기서 $fan_{\\mathrm{avg}}$은 층의 입력과 출력의 연결 개수인 $fan_{\\mathrm{in}}$과 $fan_{\\mathrm{out}}$의 평균이다.\n",
    "\n",
    "그 외에 다음과 같은 초기화 전략들이 있다.\n",
    "\n",
    "  \n",
    "| 초기화 전략 | 활성화 함수 | 정규분포 분산 |\n",
    "|--|--|--|\n",
    "| Glorot | 활성화 함수 없음, 하이퍼볼릭 탄젠트, 로지스틱, 소프트맥스 | $1/fan_{\\mathrm{avg}}$ |\n",
    "| He | ReLu 함수와 그 변종들 | $2 / fan_{\\mathrm{in}}$ |\n",
    "| LuCun | SELU | $1/fan_{\\mathrm{in}}$ |\n",
    "\n",
    "케라스는 기본적으로 균등분포의 글로럿 초기화를 사용한다. \n",
    "\n",
    "다음과 같이 층을 만들 때, ```kernerl_initializer=\"he_uniform\"```로 바꾸어 쓸 수 있다. \n",
    "\n",
    "``` keras.layer.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 활성화 함수 문제\n",
    "\n",
    "활성화 함수를 잘못 선택하면 그레디언트 소실이나 폭주로 이어질 수 있다.\n",
    "\n",
    "초기에는 생물학적 뉴런과 비슷한 시그모이드 함수가 잘 작동할 것이라고 생각되었지만, ReLu 같은 활성화 함수가 심층 신경망에서 더 잘 작동하는 경향이 있다.\n",
    "\n",
    "하지만 ReLu도 완벽하지 않고, 죽은 ReLu 문제가 알려져 있다.\n",
    "\n",
    "훈련 중 일부 뉴런이 0만 출력하는 현상이다.\n",
    "\n",
    "이 문제를 해결하기 위해 LeakyReLu, ELU, SELU 같은 변종을 사용한다.\n",
    "\n",
    "$$ \\mathrm{LeakyReLu}_{\\alpha}(z) = \\max(\\alpha z, z) $$\n",
    "\n",
    "$$ \\mathrm{ELU}_{\\alpha}(z) = \n",
    "\\left\\{ \\begin{array}{ll} \\alpha (\\exp(z) - 1) & z < 0 \\\\\n",
    "z & z \\geq 0 \\end{array} \\right.\n",
    "$$\n",
    "\n",
    "케라스에서 LeakyReLu를 사용하려면 다음과 같이 코드를 작성한다.\n",
    "\n",
    "```\n",
    "model = keras.models.Sequential([\n",
    "  [...]\n",
    "  keras.layers.Dense(10, kernel_initializer=\"he_normal\"),\n",
    "  keras.layers.LeakyReLU(alpha=0.2)\n",
    "  [...]\n",
    "])\n",
    "```\n",
    "\n",
    "SELU 함수를 사용하려면 다음과 같이 코드를 작성한다.\n",
    "\n",
    "``` lyaer = keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\") ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.6732 - accuracy: 0.4635 - val_loss: 0.8688 - val_accuracy: 0.7284\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.8265 - accuracy: 0.7329 - val_loss: 0.6980 - val_accuracy: 0.7750\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6852 - accuracy: 0.7757 - val_loss: 0.6238 - val_accuracy: 0.8006\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6227 - accuracy: 0.7942 - val_loss: 0.5794 - val_accuracy: 0.8102\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5779 - accuracy: 0.8088 - val_loss: 0.5471 - val_accuracy: 0.8238\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5576 - accuracy: 0.8145 - val_loss: 0.5254 - val_accuracy: 0.8290\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5269 - accuracy: 0.8219 - val_loss: 0.5112 - val_accuracy: 0.8342\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5134 - accuracy: 0.8254 - val_loss: 0.4959 - val_accuracy: 0.8350\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5069 - accuracy: 0.8265 - val_loss: 0.4849 - val_accuracy: 0.8392\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4946 - accuracy: 0.8319 - val_loss: 0.4786 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.6295 - accuracy: 0.5179 - val_loss: 0.8908 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8423 - accuracy: 0.7389 - val_loss: 0.7133 - val_accuracy: 0.7762\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7086 - accuracy: 0.7737 - val_loss: 0.6355 - val_accuracy: 0.7962\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6340 - accuracy: 0.7939 - val_loss: 0.5920 - val_accuracy: 0.8060\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5918 - accuracy: 0.8090 - val_loss: 0.5553 - val_accuracy: 0.8200\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5604 - accuracy: 0.8149 - val_loss: 0.5347 - val_accuracy: 0.8248\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5392 - accuracy: 0.8224 - val_loss: 0.5181 - val_accuracy: 0.8302\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5194 - accuracy: 0.8256 - val_loss: 0.4984 - val_accuracy: 0.8360\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5042 - accuracy: 0.8315 - val_loss: 0.4907 - val_accuracy: 0.8328\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4951 - accuracy: 0.8304 - val_loss: 0.4780 - val_accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배치 정규화\n",
    "\n",
    "각 층에서 활성화 함수를 통과하기 전이나 후에 정규화 연산을 추가한다.\n",
    "\n",
    "이 연산은 단순히 입력을 원점에 맞추어 정규화한 다음, 각 층에서 두 개의 새로운 파라미터로 결과값을 스케일링하고 이동시킨다.\n",
    "\n",
    "미니배치별 배치정규화층에 사용될 입력값의 표본평균과 표본표준편차를 계산한다.\n",
    "\n",
    "평균과 표준편차를 이용하여 입력값을 정규화한다. \n",
    "\n",
    "배치정규화층에는 스케일 파라미터 $\\mathbf{\\gamma}$와 오프셋 파라미터 $\\mathbf{\\beta}$가 있어 이를 이용해 배치 정규화 출력값을 계산한다.\n",
    "\n",
    "$$ \\mathbf{\\gamma} \\circ \\mathbf{\\hat x} + \\mathbf{\\beta} $$\n",
    "\n",
    "배치정규화는 신경망의 성능을 크게 향상시킨다고 알려져 있다.\n",
    "\n",
    "케라스에서는 다음의 코드로 배치 정규화를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 3ms/step - loss: 1.2209 - accuracy: 0.6011 - val_loss: 0.5620 - val_accuracy: 0.8118\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5994 - accuracy: 0.7982 - val_loss: 0.4850 - val_accuracy: 0.8360\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5302 - accuracy: 0.8137 - val_loss: 0.4486 - val_accuracy: 0.8448\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4868 - accuracy: 0.8298 - val_loss: 0.4268 - val_accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4642 - accuracy: 0.8379 - val_loss: 0.4100 - val_accuracy: 0.8590\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4431 - accuracy: 0.8470 - val_loss: 0.3981 - val_accuracy: 0.8608\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4221 - accuracy: 0.8504 - val_loss: 0.3887 - val_accuracy: 0.8648\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4193 - accuracy: 0.8521 - val_loss: 0.3808 - val_accuracy: 0.8650\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4021 - accuracy: 0.8589 - val_loss: 0.3743 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3965 - accuracy: 0.8601 - val_loss: 0.3705 - val_accuracy: 0.8676\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 활성화 함수 전에 사용하는 방법\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 1.4018 - accuracy: 0.5492 - val_loss: 0.6750 - val_accuracy: 0.7888\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7119 - accuracy: 0.7755 - val_loss: 0.5512 - val_accuracy: 0.8206\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6156 - accuracy: 0.7962 - val_loss: 0.4932 - val_accuracy: 0.8360\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5583 - accuracy: 0.8117 - val_loss: 0.4594 - val_accuracy: 0.8460\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5222 - accuracy: 0.8224 - val_loss: 0.4363 - val_accuracy: 0.8534\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4905 - accuracy: 0.8344 - val_loss: 0.4191 - val_accuracy: 0.8598\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4797 - accuracy: 0.8340 - val_loss: 0.4060 - val_accuracy: 0.8628\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4607 - accuracy: 0.8408 - val_loss: 0.3942 - val_accuracy: 0.8652\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4455 - accuracy: 0.8458 - val_loss: 0.3853 - val_accuracy: 0.8690\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4352 - accuracy: 0.8477 - val_loss: 0.3782 - val_accuracy: 0.8692\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그레이디언트 클리핑\n",
    "\n",
    "그레디언트 폭주 문제를 완화하는 방법으로 역전파 수행 시 그레디언트가 일정 임계값을 넘지 못하도록 하는 것이다.\n",
    "\n",
    "```optimizer = keras.optimizers.SGD(clipvalue=1.0)```\n",
    "\n",
    "```optimizer = keras.optimizers.SGD(clipnorm=1.0)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련된 층 재사용 하기\n",
    "\n",
    "아주 큰 DNN을 처음부터 훈련하는 것인 시간이 오래 걸리기 때문에 비슷한 유형의 문제를 처리한 신경망의 하위층을 재사용할 수 있다.\n",
    "\n",
    "(상위 층은 덜 유용함)\n",
    "\n",
    "이를 전이 학습 (transfer learning)이라 한다.\n",
    "\n",
    "먼저 재사용 층의 가중치들을 동결한다.\n",
    "\n",
    "그 다음 모델을 학습하고 평가한다.\n",
    "\n",
    "맨 위 한 두개의 은닉층의 동결을 해제하고 역전파를 통해 가중치를 조정하여 성능이 향상되는지 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 케라스를 이용한 전이 학습\n",
    "\n",
    "패션 MNIST 훈련 세트를 두 개로 나눈다.\n",
    "\n",
    "* X_train_A: 샌달과 셔츠(클래스 5와 6)을 제외한 모든 이미지\n",
    "* X_train_B: 샌달과 셔츠 이미지 중 처음 200개만 가진 작은 훈련 세트\n",
    "\n",
    "\n",
    "A 세트(8개의 클래스를 가진 분류 문제)에서 모델을 훈련하고 이를 재사용하여 B 세트(이진 분류)를 해결해 보자. \n",
    "\n",
    "A 세트의 클래스(스니커즈, 앵클 부츠, 코트, 티셔츠 등)가 B 세트에 있는 클래스(샌달과 셔츠)와 조금 비슷함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.9472 - accuracy: 0.6941 - val_loss: 0.3862 - val_accuracy: 0.8710\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.3795 - accuracy: 0.8743 - val_loss: 0.3306 - val_accuracy: 0.8866\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 3s 3ms/step - loss: 0.3262 - accuracy: 0.8880 - val_loss: 0.3035 - val_accuracy: 0.8976\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 3s 3ms/step - loss: 0.3036 - accuracy: 0.8942 - val_loss: 0.2929 - val_accuracy: 0.8989\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2942 - accuracy: 0.8983 - val_loss: 0.2858 - val_accuracy: 0.9026\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2801 - accuracy: 0.9038 - val_loss: 0.2721 - val_accuracy: 0.9101\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2692 - accuracy: 0.9064 - val_loss: 0.2698 - val_accuracy: 0.9093\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2632 - accuracy: 0.9112 - val_loss: 0.2622 - val_accuracy: 0.9121\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2570 - accuracy: 0.9116 - val_loss: 0.2582 - val_accuracy: 0.9131\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2506 - accuracy: 0.9140 - val_loss: 0.2553 - val_accuracy: 0.9128\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2541 - accuracy: 0.9122 - val_loss: 0.2497 - val_accuracy: 0.9170\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2399 - accuracy: 0.9192 - val_loss: 0.2495 - val_accuracy: 0.9155\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2413 - accuracy: 0.9170 - val_loss: 0.2468 - val_accuracy: 0.9168\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 6s 5ms/step - loss: 0.2340 - accuracy: 0.9196 - val_loss: 0.2466 - val_accuracy: 0.9180\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2323 - accuracy: 0.9190 - val_loss: 0.2429 - val_accuracy: 0.9203\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2363 - accuracy: 0.9174 - val_loss: 0.2412 - val_accuracy: 0.9185\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2310 - accuracy: 0.9210 - val_loss: 0.2486 - val_accuracy: 0.9145\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 8s 5ms/step - loss: 0.2249 - accuracy: 0.9224 - val_loss: 0.2394 - val_accuracy: 0.9183\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2222 - accuracy: 0.9224 - val_loss: 0.2418 - val_accuracy: 0.9175\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2153 - accuracy: 0.9245 - val_loss: 0.2332 - val_accuracy: 0.9203\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model B는 자체 훈련으로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 49ms/step - loss: 0.7934 - accuracy: 0.4846 - val_loss: 0.6057 - val_accuracy: 0.6998\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5309 - accuracy: 0.7613 - val_loss: 0.4777 - val_accuracy: 0.7921\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4225 - accuracy: 0.8368 - val_loss: 0.3986 - val_accuracy: 0.8580\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.3491 - accuracy: 0.8976 - val_loss: 0.3428 - val_accuracy: 0.8935\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2775 - accuracy: 0.9400 - val_loss: 0.3007 - val_accuracy: 0.9148\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2315 - accuracy: 0.9649 - val_loss: 0.2697 - val_accuracy: 0.9260\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2211 - accuracy: 0.9570 - val_loss: 0.2442 - val_accuracy: 0.9351\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1906 - accuracy: 0.9730 - val_loss: 0.2236 - val_accuracy: 0.9442\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1583 - accuracy: 0.9878 - val_loss: 0.2068 - val_accuracy: 0.9493\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.1635 - accuracy: 0.9809 - val_loss: 0.1937 - val_accuracy: 0.9554\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1479 - accuracy: 0.9828 - val_loss: 0.1819 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.1332 - accuracy: 0.9867 - val_loss: 0.1721 - val_accuracy: 0.9594\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.1470 - accuracy: 0.9714 - val_loss: 0.1640 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1268 - accuracy: 0.9867 - val_loss: 0.1566 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.1142 - accuracy: 0.9823 - val_loss: 0.1501 - val_accuracy: 0.9645\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.1039 - accuracy: 0.9944 - val_loss: 0.1441 - val_accuracy: 0.9645\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.1144 - accuracy: 0.9823 - val_loss: 0.1385 - val_accuracy: 0.9655\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1027 - accuracy: 0.9904 - val_loss: 0.1336 - val_accuracy: 0.9665\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0873 - accuracy: 0.9937 - val_loss: 0.1290 - val_accuracy: 0.9665\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0851 - accuracy: 0.9914 - val_loss: 0.1250 - val_accuracy: 0.9686\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_A와 model_B_on_A는 일부 층을 공유한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_B_on_A를 훈련할 때 model_A도 영향을 받는다. 이를 원치 않으면 ```clone_model()``` 메쏘드로 구조를 복제한 뒤 가중치를 복사해둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 model_B_on_A를 훈련할 수 있는데, 새로운 출력층이 랜덤하게 초기화되었으므로, 큰 오차를 생성할 수 있음.\n",
    "\n",
    "큰 오차 그레디언트가 재사용된 가중치를 망치지 않도록, 처음 몇 번의 에포크 동안은 재사용된 층을 동결하고 새로운 층에 적절한 가중치를 학습할 시간을 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 몇번 훈련하고, 재사용된 층의 동결을 해제한 뒤, 다시 컴파일한 다음, 훈련을 계속한다.\n",
    "\n",
    "일반적으로 재사용된 층의 동결을 해제한 후 학습률을 낮추는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 57ms/step - loss: 0.7041 - accuracy: 0.5990 - val_loss: 0.6643 - val_accuracy: 0.6379\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6278 - accuracy: 0.6544 - val_loss: 0.6176 - val_accuracy: 0.6521\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5790 - accuracy: 0.6614 - val_loss: 0.5741 - val_accuracy: 0.6765\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.5169 - accuracy: 0.7047 - val_loss: 0.5361 - val_accuracy: 0.6897\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 61ms/step - loss: 0.4127 - accuracy: 0.8063 - val_loss: 0.2890 - val_accuracy: 0.9391\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2464 - accuracy: 0.9479 - val_loss: 0.2178 - val_accuracy: 0.9675\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1809 - accuracy: 0.9819 - val_loss: 0.1802 - val_accuracy: 0.9736\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1510 - accuracy: 0.9873 - val_loss: 0.1558 - val_accuracy: 0.9787\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1246 - accuracy: 0.9914 - val_loss: 0.1375 - val_accuracy: 0.9797\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9828\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1001 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9848\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9858\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9868\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9878\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9878\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9899\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9909\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9909\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11978120356798172, 0.9739999771118164]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06532242894172668, 0.9944999814033508]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고속 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모멘텀 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네스테로프 가속 경사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adamax 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nadam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률 스케쥴링\n",
    "\n",
    "학습률을 너무 크게 잡으면 훈련이 발산할 수 있고, 너무 작게 잡으면 수렴 시간이 오래 걸릴 것이다.\n",
    "\n",
    "큰 학습률로 시작하고 학습 속도가 느려질 때 학습률을 낮추는 전략을 취할 수 있다.\n",
    "\n",
    "훈련하는 동안 학습률을 감소시키는 학습 스케쥴에는 여러가지가 있다.\n",
    "\n",
    "#### 거듭제곱 기반 스케쥴링\n",
    "\n",
    "$$lr = \\frac{lr0}{(1 + steps / s)^c}$$\n",
    "\n",
    "거듭제곱 스케쥴링은 옵티마이저를 만들 때 ```decay``` (s의 역수) 만 설정해 주면 된다. c=1임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6068 - accuracy: 0.7892 - val_loss: 0.4144 - val_accuracy: 0.8606\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3857 - accuracy: 0.8639 - val_loss: 0.3815 - val_accuracy: 0.8658\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3462 - accuracy: 0.8768 - val_loss: 0.3625 - val_accuracy: 0.8728\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3247 - accuracy: 0.8847 - val_loss: 0.3522 - val_accuracy: 0.8766\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3067 - accuracy: 0.8913 - val_loss: 0.3451 - val_accuracy: 0.8788\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2979 - accuracy: 0.8927 - val_loss: 0.3417 - val_accuracy: 0.8830\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2883 - accuracy: 0.8984 - val_loss: 0.3437 - val_accuracy: 0.8788\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2723 - accuracy: 0.9014 - val_loss: 0.3341 - val_accuracy: 0.8840\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2742 - accuracy: 0.9022 - val_loss: 0.3313 - val_accuracy: 0.8852\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2581 - accuracy: 0.9093 - val_loss: 0.3279 - val_accuracy: 0.8840\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2553 - accuracy: 0.9090 - val_loss: 0.3290 - val_accuracy: 0.8828\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2503 - accuracy: 0.9107 - val_loss: 0.3266 - val_accuracy: 0.8886\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2484 - accuracy: 0.9118 - val_loss: 0.3236 - val_accuracy: 0.8850\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2395 - accuracy: 0.9143 - val_loss: 0.3257 - val_accuracy: 0.8832\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2337 - accuracy: 0.9179 - val_loss: 0.3271 - val_accuracy: 0.8820\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2281 - accuracy: 0.9201 - val_loss: 0.3192 - val_accuracy: 0.8890\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2285 - accuracy: 0.9186 - val_loss: 0.3188 - val_accuracy: 0.8908\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2253 - accuracy: 0.9218 - val_loss: 0.3176 - val_accuracy: 0.8882\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2194 - accuracy: 0.9225 - val_loss: 0.3209 - val_accuracy: 0.8870\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2131 - accuracy: 0.9261 - val_loss: 0.3158 - val_accuracy: 0.8886\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2100 - accuracy: 0.9276 - val_loss: 0.3200 - val_accuracy: 0.8866\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2122 - accuracy: 0.9255 - val_loss: 0.3147 - val_accuracy: 0.8878\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2061 - accuracy: 0.9283 - val_loss: 0.3193 - val_accuracy: 0.8846\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2029 - accuracy: 0.9294 - val_loss: 0.3137 - val_accuracy: 0.8866\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2090 - accuracy: 0.9295 - val_loss: 0.3192 - val_accuracy: 0.8844\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지수 기반 스케쥴링\n",
    "\n",
    "```lr = lr0 * 0.1**(epoch / s)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 12s 6ms/step - loss: 1.1843 - accuracy: 0.7133 - val_loss: 1.0511 - val_accuracy: 0.6774\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.8213 - accuracy: 0.7070 - val_loss: 1.0220 - val_accuracy: 0.6812\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.7461 - accuracy: 0.7258 - val_loss: 0.7836 - val_accuracy: 0.7120\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.7095 - accuracy: 0.7358 - val_loss: 0.7549 - val_accuracy: 0.7502\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.6266 - accuracy: 0.7501 - val_loss: 0.6525 - val_accuracy: 0.7328\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6076 - accuracy: 0.7586 - val_loss: 0.6814 - val_accuracy: 0.7614\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5492 - accuracy: 0.7702 - val_loss: 0.6625 - val_accuracy: 0.7768\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5473 - accuracy: 0.7779 - val_loss: 0.6111 - val_accuracy: 0.7816\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5068 - accuracy: 0.7831 - val_loss: 0.5899 - val_accuracy: 0.7944\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4895 - accuracy: 0.7976 - val_loss: 0.5778 - val_accuracy: 0.7964\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4274 - accuracy: 0.8406 - val_loss: 1.0939 - val_accuracy: 0.8040\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4213 - accuracy: 0.8494 - val_loss: 0.5937 - val_accuracy: 0.8498\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3681 - accuracy: 0.8695 - val_loss: 0.5106 - val_accuracy: 0.8554\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3408 - accuracy: 0.8776 - val_loss: 0.5576 - val_accuracy: 0.8540\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3280 - accuracy: 0.8836 - val_loss: 0.5047 - val_accuracy: 0.8618\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2974 - accuracy: 0.8962 - val_loss: 0.4935 - val_accuracy: 0.8672\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2823 - accuracy: 0.9023 - val_loss: 0.5373 - val_accuracy: 0.8678\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2613 - accuracy: 0.9096 - val_loss: 0.5139 - val_accuracy: 0.8776\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2416 - accuracy: 0.9189 - val_loss: 0.5406 - val_accuracy: 0.8796\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2318 - accuracy: 0.9257 - val_loss: 0.5428 - val_accuracy: 0.8758\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2195 - accuracy: 0.9277 - val_loss: 0.5484 - val_accuracy: 0.8814\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2074 - accuracy: 0.9317 - val_loss: 0.5390 - val_accuracy: 0.8846\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1964 - accuracy: 0.9369 - val_loss: 0.5644 - val_accuracy: 0.8814\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1890 - accuracy: 0.9386 - val_loss: 0.5857 - val_accuracy: 0.8822\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1738 - accuracy: 0.9428 - val_loss: 0.5758 - val_accuracy: 0.8816\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 외에\n",
    "\n",
    "* 구간별 고정 스케쥴링\n",
    "* 성능 기반 스케쥴링\n",
    "* 1 사이클 스케쥴링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 규제를 통한 과대적합 피하기\n",
    "\n",
    "#### $\\ell_1$과 $\\ell_2$ 규제\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3166 - accuracy: 0.7925 - val_loss: 0.7429 - val_accuracy: 0.8226\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.7353 - accuracy: 0.8212 - val_loss: 0.6830 - val_accuracy: 0.8430\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 드롭아웃\n",
    "\n",
    "드롭아웃은 심층 신경망에서 인기 있는 규제로 잘 작동된다고 입증되었다.\n",
    "\n",
    "매 훈련 각 스텝에서 각 뉴런은 임시적으로 드롭아웃될 확률 p를 가진다.\n",
    "\n",
    "즉, 이번 훈련에는 무시되어도 다음 훈련에서는 활성화 될 수 있다.\n",
    "\n",
    "훈련이 끝난 후에는 드랍아웃을 적용하지 않는다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.7464 - accuracy: 0.7580 - val_loss: 0.3824 - val_accuracy: 0.8644\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4303 - accuracy: 0.8414 - val_loss: 0.3513 - val_accuracy: 0.8700\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
