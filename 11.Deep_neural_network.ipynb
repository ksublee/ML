{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층 신경망 훈련하기\n",
    "\n",
    "심층 신경망 훈련 도중 다음과 같은 상황을 마주할 수 있다.\n",
    "\n",
    "* 까다로운 그레디언트 소실 또는 그레디언트 폭주 문제에 직면할 수 있음. 심층 신경망 아래쪽으로 갈수록 그레디언트가 점점 작아지거나 커지는 현상\n",
    "\n",
    "* 대규모 신경망을 훈련하기 위한 데이터가 충분치 않거나 레이블을 만드는데 비용이 많이 듬\n",
    "\n",
    "* 훈련이 극단적으로 느려짐\n",
    "\n",
    "* 수백만개의 파라미터를 가진 모델은 과적합될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그레디언트 소실, 폭주 문제\n",
    "\n",
    "역전파 알고리즘이 하위층으로 진행될스록 그레디언트가 작아지거나 커지는 현상은 훈련을 어렵게 한다.\n",
    "\n",
    "의심되는 원인으로서 많이 사용되는 로지스틱 시그모이드 활성화 함수와, 표준정규분포 가중치 초기화 방법이 거론된다.\n",
    "\n",
    "로지스틱 함수는 입력인 양수나 음수로 커지면 기울기가 0에 매우 가까워진다.\n",
    "\n",
    "역전파가 될 때, 전달될 그레디언트가 거의 없고, 조금 있는 그레디언트는 최상위층으로부터 진행되며 점점 약해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가중치 초기화 방법\n",
    "\n",
    "로지스틱 함수를 이용할 때, 각 층의 연결 가중치를 아래의 식대로 무작위로 초기화하면 그레디언트 문제를 완화할 수 있다.\n",
    "\n",
    "이를 Xavier initialization라고 한다.\n",
    "\n",
    "$$ \\text{Normal distribution with mean 0 and variance } \\sigma = \\sqrt{\\frac{1}{fan_{\\mathrm{avg}}}} $$\n",
    "$$ \\text{ or a uniform distribution between } -r \\text{ and } r, \\text{ with } r = \\sqrt{\\frac{2}{fan_{\\mathrm{avg}}}} $$\n",
    "\n",
    "여기서 $fan_{\\mathrm{avg}}$은 층의 입력과 출력의 연결 개수인 $fan_{\\mathrm{in}}$과 $fan_{\\mathrm{out}}$의 평균이다.\n",
    "\n",
    "그 외에 다음과 같은 초기화 전략들이 있다.\n",
    "\n",
    "  \n",
    "| 초기화 전략 | 활성화 함수 | 정규분포 분산 |\n",
    "|--|--|--|\n",
    "| Glorot | 활성화 함수 없음, 하이퍼볼릭 탄젠트, 로지스틱, 소프트맥스 | $1/fan_{\\mathrm{avg}}$ |\n",
    "| He | ReLu 함수와 그 변종들 | $2 / fan_{\\mathrm{in}}$ |\n",
    "| LuCun | SELU | $1/fan_{\\mathrm{in}}$ |\n",
    "\n",
    "케라스는 기본적으로 균등분포의 글로럿 초기화를 사용한다. \n",
    "\n",
    "다음과 같이 층을 만들 때, ```kernerl_initializer=\"he_uniform\"```로 바꾸어 쓸 수 있다. \n",
    "\n",
    "``` keras.layer.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 활성화 함수 문제\n",
    "\n",
    "활성화 함수를 잘못 선택하면 그레디언트 소실이나 폭주로 이어질 수 있다.\n",
    "\n",
    "초기에는 생물학적 뉴런과 비슷한 시그모이드 함수가 잘 작동할 것이라고 생각되었지만, ReLu 같은 활성화 함수가 심층 신경망에서 더 잘 작동하는 경향이 있다.\n",
    "\n",
    "하지만 ReLu도 완벽하지 않고, 죽은 ReLu 문제가 알려져 있다.\n",
    "\n",
    "훈련 중 일부 뉴런이 0만 출력하는 현상이다.\n",
    "\n",
    "이 문제를 해결하기 위해 LeakyReLu, ELU, SELU 같은 변종을 사용한다.\n",
    "\n",
    "$$ \\mathrm{LeakyReLu}_{\\alpha}(z) = \\max(\\alpha z, z) $$\n",
    "\n",
    "$$ \\mathrm{ELU}_{\\alpha}(z) = \n",
    "\\left\\{ \\begin{array}{ll} \\alpha (\\exp(z) - 1) & z < 0 \\\\\n",
    "z & z \\geq 0 \\end{array} \\right.\n",
    "$$\n",
    "\n",
    "케라스에서 LeakyReLu를 사용하려면 다음과 같이 코드를 작성한다.\n",
    "\n",
    "```\n",
    "model = keras.models.Sequential([\n",
    "  [...]\n",
    "  keras.layers.Dense(10, kernel_initializer=\"he_normal\"),\n",
    "  keras.layers.LeakyReLU(alpha=0.2)\n",
    "  [...]\n",
    "])\n",
    "```\n",
    "\n",
    "SELU 함수를 사용하려면 다음과 같이 코드를 작성한다.\n",
    "\n",
    "``` lyaer = keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\") ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.6314 - accuracy: 0.5054 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8416 - accuracy: 0.7247 - val_loss: 0.7130 - val_accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7053 - accuracy: 0.7638 - val_loss: 0.6427 - val_accuracy: 0.7900\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6325 - accuracy: 0.7908 - val_loss: 0.5900 - val_accuracy: 0.8064\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5992 - accuracy: 0.8020 - val_loss: 0.5582 - val_accuracy: 0.8200\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5624 - accuracy: 0.8141 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5379 - accuracy: 0.8217 - val_loss: 0.5156 - val_accuracy: 0.8304\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5152 - accuracy: 0.8296 - val_loss: 0.5079 - val_accuracy: 0.8280\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5100 - accuracy: 0.8269 - val_loss: 0.4895 - val_accuracy: 0.8386\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4918 - accuracy: 0.8340 - val_loss: 0.4817 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.6965 - accuracy: 0.4881 - val_loss: 0.8951 - val_accuracy: 0.7194\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8559 - accuracy: 0.7299 - val_loss: 0.7103 - val_accuracy: 0.7742\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7083 - accuracy: 0.7699 - val_loss: 0.6404 - val_accuracy: 0.7958\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6353 - accuracy: 0.7901 - val_loss: 0.5859 - val_accuracy: 0.8128\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6011 - accuracy: 0.8011 - val_loss: 0.5542 - val_accuracy: 0.8192\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5645 - accuracy: 0.8133 - val_loss: 0.5314 - val_accuracy: 0.8242\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5398 - accuracy: 0.8181 - val_loss: 0.5121 - val_accuracy: 0.8318\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5174 - accuracy: 0.8262 - val_loss: 0.5043 - val_accuracy: 0.8346\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5121 - accuracy: 0.8258 - val_loss: 0.4869 - val_accuracy: 0.8400\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4933 - accuracy: 0.8320 - val_loss: 0.4791 - val_accuracy: 0.8414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배치 정규화\n",
    "\n",
    "각 층에서 활성화 함수를 통과하기 전이나 후에 정규화 연산을 추가한다.\n",
    "\n",
    "이 연산은 단순히 입력을 원점에 맞추어 정규화한 다음, 각 층에서 두 개의 새로운 파라미터로 결과값을 스케일링하고 이동시킨다.\n",
    "\n",
    "미니배치별 배치정규화층에 사용될 입력값의 표본평균과 표본표준편차를 계산한다.\n",
    "\n",
    "평균과 표준편차를 이용하여 입력값을 정규화한다. \n",
    "\n",
    "배치정규화층에는 스케일 파라미터 $\\mathbf{\\gamma}$와 오프셋 파라미터 $\\mathbf{\\beta}$가 있어 이를 이용해 배치 정규화 출력값을 계산한다.\n",
    "\n",
    "$$ \\mathbf{\\gamma} \\circ \\mathbf{\\hat x} + \\mathbf{\\beta} $$\n",
    "\n",
    "배치정규화는 신경망의 성능을 크게 향상시킨다고 알려져 있다.\n",
    "\n",
    "케라스에서는 다음의 코드로 배치 정규화를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.1669 - accuracy: 0.6144 - val_loss: 0.5548 - val_accuracy: 0.8134\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6000 - accuracy: 0.7937 - val_loss: 0.4757 - val_accuracy: 0.8364\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5274 - accuracy: 0.8153 - val_loss: 0.4405 - val_accuracy: 0.8524\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4883 - accuracy: 0.8306 - val_loss: 0.4185 - val_accuracy: 0.8580\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4721 - accuracy: 0.8356 - val_loss: 0.4025 - val_accuracy: 0.8616\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4426 - accuracy: 0.8432 - val_loss: 0.3908 - val_accuracy: 0.8670\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4282 - accuracy: 0.8508 - val_loss: 0.3807 - val_accuracy: 0.8704\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4124 - accuracy: 0.8549 - val_loss: 0.3742 - val_accuracy: 0.8738\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4060 - accuracy: 0.8557 - val_loss: 0.3686 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3892 - accuracy: 0.8624 - val_loss: 0.3635 - val_accuracy: 0.8766\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 활성화 함수 전에 사용하는 방법\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.3856 - accuracy: 0.5573 - val_loss: 0.6611 - val_accuracy: 0.7864\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6956 - accuracy: 0.7784 - val_loss: 0.5478 - val_accuracy: 0.8196\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6015 - accuracy: 0.8004 - val_loss: 0.4968 - val_accuracy: 0.8332\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5469 - accuracy: 0.8162 - val_loss: 0.4662 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5213 - accuracy: 0.8204 - val_loss: 0.4438 - val_accuracy: 0.8498\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4883 - accuracy: 0.8311 - val_loss: 0.4278 - val_accuracy: 0.8528\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4733 - accuracy: 0.8363 - val_loss: 0.4141 - val_accuracy: 0.8562\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4523 - accuracy: 0.8428 - val_loss: 0.4035 - val_accuracy: 0.8592\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4470 - accuracy: 0.8446 - val_loss: 0.3948 - val_accuracy: 0.8610\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4278 - accuracy: 0.8516 - val_loss: 0.3869 - val_accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그레이디언트 클리핑\n",
    "\n",
    "그레디언트 폭주 문제를 완화하는 방법으로 역전파 수행 시 그레디언트가 일정 임계값을 넘지 못하도록 하는 것이다.\n",
    "\n",
    "```optimizer = keras.optimizers.SGD(clipvalue=1.0)```\n",
    "\n",
    "```optimizer = keras.optimizers.SGD(clipnorm=1.0)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련된 층 재사용 하기\n",
    "\n",
    "아주 큰 DNN을 처음부터 훈련하는 것인 시간이 오래 걸리기 때문에 비슷한 유형의 문제를 처리한 신경망의 하위층을 재사용할 수 있다.\n",
    "\n",
    "(상위 층은 덜 유용함)\n",
    "\n",
    "이를 전이 학습 (transfer learning)이라 한다.\n",
    "\n",
    "먼저 재사용 층의 가중치들을 동결한다.\n",
    "\n",
    "그 다음 모델을 학습하고 평가한다.\n",
    "\n",
    "맨 위 한 두개의 은닉층의 동결을 해제하고 역전파를 통해 가중치를 조정하여 성능이 향상되는지 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 케라스를 이용한 전이 학습\n",
    "\n",
    "패션 MNIST 훈련 세트를 두 개로 나눈다.\n",
    "\n",
    "* X_train_A: 샌달과 셔츠(클래스 5와 6)을 제외한 모든 이미지\n",
    "* X_train_B: 샌달과 셔츠 이미지 중 처음 200개만 가진 작은 훈련 세트\n",
    "\n",
    "\n",
    "A 세트(8개의 클래스를 가진 분류 문제)에서 모델을 훈련하고 이를 재사용하여 B 세트(이진 분류)를 해결해 보자. \n",
    "\n",
    "A 세트의 클래스(스니커즈, 앵클 부츠, 코트, 티셔츠 등)가 B 세트에 있는 클래스(샌달과 셔츠)와 조금 비슷함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 4s 2ms/step - loss: 0.8501 - accuracy: 0.7172 - val_loss: 0.3924 - val_accuracy: 0.8592\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3753 - accuracy: 0.8722 - val_loss: 0.3317 - val_accuracy: 0.8884\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3251 - accuracy: 0.8888 - val_loss: 0.3038 - val_accuracy: 0.8959\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3109 - accuracy: 0.8929 - val_loss: 0.2891 - val_accuracy: 0.9008\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2889 - accuracy: 0.8980 - val_loss: 0.2793 - val_accuracy: 0.9028\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2771 - accuracy: 0.9048 - val_loss: 0.2728 - val_accuracy: 0.9053\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2699 - accuracy: 0.9075 - val_loss: 0.2731 - val_accuracy: 0.9068\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2704 - accuracy: 0.9081 - val_loss: 0.2626 - val_accuracy: 0.9123\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2619 - accuracy: 0.9112 - val_loss: 0.2574 - val_accuracy: 0.9126\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2593 - accuracy: 0.9139 - val_loss: 0.2547 - val_accuracy: 0.9111\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 3s 3ms/step - loss: 0.2483 - accuracy: 0.9163 - val_loss: 0.2504 - val_accuracy: 0.9160\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2500 - accuracy: 0.9145 - val_loss: 0.2528 - val_accuracy: 0.9153\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2422 - accuracy: 0.9171 - val_loss: 0.2455 - val_accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2329 - accuracy: 0.9214 - val_loss: 0.2444 - val_accuracy: 0.9173\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2294 - accuracy: 0.9228 - val_loss: 0.2492 - val_accuracy: 0.9158\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2345 - accuracy: 0.9204 - val_loss: 0.2406 - val_accuracy: 0.9198\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2248 - accuracy: 0.9236 - val_loss: 0.2438 - val_accuracy: 0.9188\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2230 - accuracy: 0.9244 - val_loss: 0.2501 - val_accuracy: 0.9096\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2245 - accuracy: 0.9234 - val_loss: 0.2376 - val_accuracy: 0.9185\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2173 - accuracy: 0.9250 - val_loss: 0.2363 - val_accuracy: 0.9203\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 44ms/step - loss: 0.9967 - accuracy: 0.5075 - val_loss: 0.5225 - val_accuracy: 0.7515\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4764 - accuracy: 0.7900 - val_loss: 0.4004 - val_accuracy: 0.8408\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3496 - accuracy: 0.8775 - val_loss: 0.3317 - val_accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2798 - accuracy: 0.9325 - val_loss: 0.2840 - val_accuracy: 0.9047\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2451 - accuracy: 0.9275 - val_loss: 0.2522 - val_accuracy: 0.9239\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2217 - accuracy: 0.9417 - val_loss: 0.2289 - val_accuracy: 0.9351\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1759 - accuracy: 0.9666 - val_loss: 0.2121 - val_accuracy: 0.9351\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1785 - accuracy: 0.9564 - val_loss: 0.1960 - val_accuracy: 0.9402\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1471 - accuracy: 0.9779 - val_loss: 0.1803 - val_accuracy: 0.9493\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1510 - accuracy: 0.9598 - val_loss: 0.1695 - val_accuracy: 0.9493\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1256 - accuracy: 0.9789 - val_loss: 0.1596 - val_accuracy: 0.9523\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1225 - accuracy: 0.9818 - val_loss: 0.1518 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1023 - accuracy: 0.9855 - val_loss: 0.1447 - val_accuracy: 0.9604\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0861 - accuracy: 0.9897 - val_loss: 0.1375 - val_accuracy: 0.9645\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0942 - accuracy: 0.9849 - val_loss: 0.1311 - val_accuracy: 0.9655\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0861 - accuracy: 0.9944 - val_loss: 0.1265 - val_accuracy: 0.9665\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0899 - accuracy: 0.9894 - val_loss: 0.1222 - val_accuracy: 0.9665\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0847 - accuracy: 0.9950 - val_loss: 0.1184 - val_accuracy: 0.9665\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0679 - accuracy: 0.9981 - val_loss: 0.1148 - val_accuracy: 0.9675\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0665 - accuracy: 0.9981 - val_loss: 0.1119 - val_accuracy: 0.9686\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
