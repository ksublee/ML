{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling method\n",
    "\n",
    "Resampling은 통계학에서 자주 이용되는 방법이다.\n",
    "\n",
    "훈련 데이터로부터 데이터를 다시 뽑는 resampling 방법을 이용하여 적합된 모형에 대해 더 많은 정보를 얻을 수 있다.\n",
    "\n",
    "주로 사용되는 resampling 방법에는 크게 두 가지가 있다.\n",
    "\n",
    "* cross-validation\n",
    "\n",
    "* bootstrap\n",
    "\n",
    "두 방법 모두 통계적 학습에서 유용하게 사용된다.\n",
    "\n",
    "Cross-validation은 테스트 에러를 추정하고, 모형의 성능을 측정하고, 적합한 flexibility를 가지는 모형을 선택할 수 있게 한다.\n",
    "\n",
    "Bootstrap은 모수 추정에 대한 정확성을 측정할 수 있게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "통계적 학습의 과정에서 항상 test error와 training error를 구분해야 한다.\n",
    "\n",
    "테스트 에러가 작은 모형이 좋은 모형이다.\n",
    "\n",
    "만약 테스트 데이터가 충분히 있다면 테스트 에러를 쉽게 계산할 수 있지만 항상 그런 것은 아니다.\n",
    "\n",
    "일반적으로 데이터의 일부는 트레이닝에 사용하고, 나머지는 남겨두어 테스트에 사용한다.\n",
    "\n",
    "테스트에 사용하는 부분을 validation set 혹은 hold-out set이라고도 한다.\n",
    "\n",
    "트레이닝 셋을 이용하여 모델을 적합하고, validation set을 이용하여 테스트 에러를 추정한다.\n",
    "\n",
    "* 질적 변수에서는 MSE 등을 이용하고, 양적 변수에서는 misclassiffication rate을 이용한다.\n",
    "\n",
    "가장 간단한 방법은 데이터 셋을 랜덤으로 나누어 하나는 훈련에 다른 하나는 테스트 에러 추정에 사용하는 것이다.\n",
    "\n",
    "<img src=\"image/split.png\" width=\"500\">\n",
    "\n",
    "Validation set에 어떤 데이터가 속하는지는 순전히 랜덤으로 결정되기 때문에, 이 랜덤성에 따라 테스트 에러에 대한 추정치는 크게 변동할 수 있다.\n",
    "\n",
    "또한 위 방법은 트레이닝에 전체 데이터의 절반만 이용되기 때문에, 전체 데이터를 사용하는 것보다 fitting이 부정확하게 이루어지고, 이에 따라 validation set을 이용한 test error의 추정치는 overestimate 될 가능성이 높다.\n",
    "\n",
    "<img src=\"image/validation_error.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross-Validation\n",
    "\n",
    "LOOCV 방법은 앞의 validation 방법과 비슷하나 단점을 보완하였다.\n",
    "\n",
    "비슷한 크기로 두 셋을 나누는 대신, 하나의 관찰값 $(x_1, y_1)$이 validation에 사용된다.\n",
    "\n",
    "나머지 데이터는 트레이닝에 이용하고, 적합이 끝나면 적합된 모형을 이용해 예측값 $\\hat y_1$을 계산한다.\n",
    "\n",
    "테스트 에러에 대한 추정치는 $\\mathrm{MSE}_1 = (y_1 - \\hat y_1)^2 $이다.\n",
    "\n",
    "이는 테스트 에러에 대해 unbiased지만 분산이 매우 클 것이다.\n",
    "\n",
    "다음에는 $(x_2, y_2)$를 validation set으로 두고, 나머지 데이터를 이용해 모형 적합을 거쳐, $\\mathrm{MSE}_2 = (y_2 - \\hat y_2)^2 $를 계산한다.\n",
    "\n",
    "모든 데이터에 대해 위 과정을 반복하고, $\\mathrm{MSE}_i$들을 계산할 수 있다.\n",
    "\n",
    "테스트 MSE에 대한 LOOCV 추정량은 다음과 같다.\n",
    "\n",
    "$$ \\mathrm{CV}_{(n)} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathrm{MSE}_{i} $$\n",
    "\n",
    "이를 그림으로 표현하면 다음과 같다.\n",
    "\n",
    "<img src=\"image/LOOCV.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold Cross-Validation\n",
    "\n",
    "LOOCV는 많은 장점을 지녔지만, 데이터의 총 수가 많으면 상당히 오랜 시간이 걸린다.\n",
    "\n",
    "이 경우 k-fold CV 방법은 LOOCV의 대안이 된다.\n",
    "\n",
    "k-fold 방법에서는 데이터를 랜덤하게 $k$ 개의 그룹으로 나눈다.\n",
    "\n",
    "이 중 한 그룹이 validation set이고 나머지는 훈련에 사용된다. 훈련이 끝난 모형으로 validation set에 대해 MSE를 측정할 수 있다.\n",
    "\n",
    "LOOCV의 경우와 마찬가지로, 모든 $k$ 개의 그룹이 validation set이 될 수 있으며, 이 때마다 나머지 그룹들이 훈련을 담당한다.\n",
    "\n",
    "따라서 각 그룹에 대해 MSE가 측정되면 이것의 평균으로 테스트 에러에 대한 추정치를 계산한다.\n",
    "\n",
    "$$ \\mathrm{CV}_k = \\frac{1}{k} \\sum_{i=1}^{k} \\mathrm{MSE}_i $$\n",
    "\n",
    "아래 그림은 k-fold cross validation을 나타낸다.\n",
    "\n",
    "<img src=\"image/kfold.png\" width=\"600\">\n",
    "\n",
    "다음은 시뮬레이션 데이터를 이용하여 계산한 true test MSE와 추정된 test MSE의 비교이다.\n",
    "\n",
    "<img src=\"image/k_fold_MSE.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-variance trade-off for k-fold cross-validation\n",
    "\n",
    "k-fold CV는 계산 비용 측면에서 LOOCV보다 유리할 뿐 아니라, 종종 LOOCV 보다 더 정확한 test error를 계산한다.\n",
    "\n",
    "* LOOCV는 한번에 거의 모든 데이터를 트레이닝에 사용하기 때문에, bias를 줄이는 데에 있어서는 k-fold CV 보다 우월하다.\n",
    "\n",
    "* 반면 k-fold CV는 variance 측면에서 LOOCV보다 나은 모습을 보인다. 이는 LOOCV의 훈련 데이터들은 겹치는 부분이 많기 때문에 높은 상관관계를 지니지만, k-fold CV는 겹치는 부분이 상대적으로 적기 때문이다.\n",
    "\n",
    "  * 높은 상관관계를 지니는 값들의 표본평균은 상관관계가 없는 값들의 표본평균보다 높은 분산을 가진다.\n",
    "\n",
    "적절한 k를 선택하는 문제는 결국 bias-variance trade-off 문제이며, 일반적으로 $k=5$ 혹은 $k=10$의 값이 이용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation on classification problems\n",
    "\n",
    "위에서는 $Y$가 양적 변수라고 가정하고 MSE를 이용하였다.\n",
    "\n",
    "$Y$가 질적 변수일때도 마찬가지의 논의를 할 수 있다.\n",
    "\n",
    "이 경우, LOOCV error rate은 다음과 같다.\n",
    "\n",
    "$$ \\mathrm{CV}_{(n)} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathrm{Err}_{i}, \\quad \\mathrm{Err}_{i} = \\mathbb I _{y_i \\neq \\hat y_i}.  $$\n",
    "\n",
    "k-fold CV error rate 또한 마찬가지로 정의된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주의할 점\n",
    "\n",
    "예를들어 5000개의 predictor 중 $Y$와 상관관계가 높은 100개의 predictor를 선택하여 logistic regression 등의 작업을 진행한다고 가정하자.\n",
    "\n",
    "Cross-validation 방법을 적용할 때 주의할 점은 5000개의 predictor 중 100개를 선택하는 과정도 training에 포함되기 때문에, 전체 데이터가 아닌 training set만을 이용하여 100개의 predictor를 선택하여야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap\n",
    "\n",
    "Bootstrap은 통계학에서 estimator의 정확성을 측정하는데 사용할 수 있는 유연하고 강력한 방법이다.\n",
    "\n",
    "추정량의 표준오차나 신뢰구간을 계산하는 데에 사용할 수 있다.\n",
    "\n",
    "만약 모집단의 분포를 이미 알고 있다면 시뮬레이션 방법을 통해 샘플을 계속 생성할 수 있다.\n",
    "\n",
    "Bootstrap은 주어진 샘플을 다시 resampling하여 새로운 샘플을 만드는 과정이다.\n",
    "\n",
    "* sampling with replacement\n",
    "\n",
    "<img src=\"image/bootstrap.png\" width=\"450\">\n",
    "\n",
    "모수 $\\alpha$에 대한 추정치는 각 bootstrap 단계인 $Z^{*r}$마다 계산할 수 있다. 이를 $\\hat \\alpha^{*r}$라 하자.\n",
    "\n",
    "Bootstrap 방법에 의한 $\\alpha$의 추정량의 표준오차는 다음으로 추정한다.\n",
    "\n",
    "$$ \\mathrm{SE}_B (\\hat \\alpha) = \\sqrt{\\frac{1}{B-1} \\sum_{r=1}^{B} \\left( \\hat \\alpha^{*r} - \\overline{ \\hat \\alpha^{*}} \\right)^2} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
