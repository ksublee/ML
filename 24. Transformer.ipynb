{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2137ac01-0128-4853-aa68-75a50cfb94e7",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "- Transformer는 **Self-Attention** 메커니즘을 활용해 입력 시퀀스 내 요소들 간의 관계를 동시 처리하는 딥러닝 모델\n",
    "\n",
    "- 인코더-디코더 구조를 갖고 있으며, 각각 다층의 attention 및 feedforward 레이어로 구성\n",
    "\n",
    "- 앞 단원에서는 순환 신경망을 거친 encoder output과 마찬가지로 순환 신경망을 거쳐 나온 디코더 아웃풋 간의 attention 구조를 살펴보았다.\n",
    "\n",
    "- Transformer는 순환 신경망 과정을 생략하고 대신 self-attention 구조를 이용.\n",
    "\n",
    "- 순차적인 처리 없이도 병렬 연산이 가능해, 번역·요약·질문응답 등 다양한 자연어 처리 작업에서 뛰어난 성능을 보임\n",
    "\n",
    "- 과목 특성상 자연어 처리작업을 하기는 어려우므로 이 단원에서는 Transformer의 구조에 대해 간략히 알아본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d064e78e-b453-4c4a-93d3-72d21b9a3dce",
   "metadata": {},
   "source": [
    "## Positional encoding\n",
    "\n",
    "Transformer 아키텍처는 기본적으로 순서에 의존하지 않는 구조인 self-attention 메커니즘을 기반으로 한다.   \n",
    "    \n",
    "추후 알아볼 self-attention은 입력 시퀀스를 처리할 때 각 위치의 값들이 서로 독립적으로 처리되므로, 순서 정보가 내재되어 있지 않다. \n",
    "- RNN과 같은 전통적인 시퀀스 모델들은 자연스럽게 순서를 처리하지만, Transformer는 병렬 처리가 가능하도록 설계되어 순서 정보가 내재되어 있지 않다.\n",
    "\n",
    "따라서, 시퀀스의 순서 정보를 모델에 제공하기 위해 positional encoding을 도입하여, 입력 시퀀스의 각 위치에 대한 순서 정보를 학습할 수 있게 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f6914-a659-4c25-af83-09f66066fcf1",
   "metadata": {},
   "source": [
    "### Positional Encoding 방식\n",
    "\n",
    "Transformer에서 사용되는 대표적인 positional encoding 방식은 사인과 코사인 함수를 사용한다. \n",
    "\n",
    "각 차원에 대해 다른 주기를 가지는 사인과 코사인 값을 사용하여 각 위치의 인코딩을 생성한다.\n",
    "\n",
    "이러한 방식은 시퀀스의 길이에 관계없이 위치 정보를 제공할 수 있고, 모델이 이를 통해 위치 정보를 학습할 수 있도록 돕는다.\n",
    "\n",
    "Positional enconding에 사용되는 수식은 다음과 같다.\n",
    "\n",
    "$$\\textrm{PE}{(p, 2i)} = \\sin\\left(\\frac{p}{N^{2i/d}} \\right), \\quad \\textrm{PE}{(p, 2i+1)} = \\cos\\left(\\frac{p}{N^{2i/d}}\\right)$$\n",
    "\n",
    "- $p$ : 시간축에 대한 인덱스\n",
    "- $2i, 2i+1$ : 입력 시퀀스의 차원에 대한 인덱스, 각, 짝수와 홀수 인덱스를 의미\n",
    "- $N$ : 큰 양수\n",
    "- $d$ : 입력 시퀀스의 차원\n",
    "\n",
    "`numpy`를 이용해 간단히 표현하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473d0130-9fbf-41db-88d8-4d0294f71ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.          0.          1.        ]\n",
      " [ 0.84147098  0.54030231  0.00999983  0.99995   ]\n",
      " [ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      " [ 0.14112001 -0.9899925   0.0299955   0.99955003]\n",
      " [-0.7568025  -0.65364362  0.03998933  0.99920011]\n",
      " [-0.95892427  0.28366219  0.04997917  0.99875026]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Define sequence length and model dimension\n",
    "timestep = 6\n",
    "dim = 4\n",
    "\n",
    "pe = np.zeros((timestep, dim))\n",
    "    \n",
    "# Calculate the position indices for the sequence\n",
    "position = np.arange(0, timestep)[:, np.newaxis]\n",
    "\n",
    "N = 10000.0\n",
    "# Calculate the dimension indices\n",
    "div_term = 1 / np.power(N, np.arange(0, dim, 2) / dim)\n",
    "\n",
    "# Apply the sin function to even indices and cos function to odd indices\n",
    "pe[:, 0::2] = np.sin(position * div_term)  # Apply sin to even indices\n",
    "pe[:, 1::2] = np.cos(position * div_term)  # Apply cos to odd indices\n",
    "\n",
    "# Print the positional encoding matrix\n",
    "print(pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af97fb29-29b9-4e97-a531-45060bea6b8a",
   "metadata": {},
   "source": [
    "위에서 출력된 행렬의 행은 시간축이고, 열은 입력 시퀀스의 차원을 나타낸다.\n",
    "\n",
    "같은 거리에 있는 positional encoding 벡터들을 내적하였을 때, 동일한 값을 가짐을 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1966770f-8aaa-493d-ae1c-978b4af60cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.540252306284805,\n",
       " 1.5402523062848048,\n",
       " 1.540252306284805,\n",
       " 1.540252306284805,\n",
       " 1.540252306284805)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[0, :] @ pe[1, :], pe[1, :] @ pe[2, :], pe[2, :] @ pe[3, :], pe[3, :] @ pe[4, :], pe[4, :] @ pe[5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec15fe38-3f74-4c22-b91d-c27075f5d842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5836531701194354,\n",
       " 0.5836531701194354,\n",
       " 0.5836531701194354,\n",
       " 0.5836531701194355)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[0, :] @ pe[2, :], pe[1, :] @ pe[3, :], pe[2, :] @ pe[4, :], pe[3, :] @ pe[5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377816c5-18ae-43cd-b2b5-0486ed27de1c",
   "metadata": {},
   "source": [
    "Positional encoding을 담당하는 keras layer를 클래스로 정의하여 보자.\n",
    "\n",
    "- `class PositionalEncoding(layers.Layer):` TensorFlow/Keras에서 사용자 정의 레이어를 만들기 위한 정의\n",
    "\n",
    "  - `layers.Layer`를 상속했기 때문에 Keras의 커스텀 레이어가 됨\n",
    " \n",
    "  - 이 레이어는 `__init__`, `call`, 등의 메서드를 통해 정의된 사용자 정의 동작을 수행할 수 있음\n",
    "\n",
    "- 편의상, 이 코드는 짝수의 `dim`에 대해서만 작동하도록 만들었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6005d577-0923-4cc9-abf9-bd0923b812e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pos_encoding = np.zeros((max_len, dim))\n",
    "        positions = np.arange(0, max_len)[:, np.newaxis]\n",
    "\n",
    "        N = 10000.0\n",
    "        div_term =  1 / np.power(N, np.arange(0, dim, 2) / dim)\n",
    "        \n",
    "        pos_encoding[:, 0::2] = np.sin(positions * div_term)\n",
    "        pos_encoding[:, 1::2] = np.cos(positions * div_term)\n",
    "        \n",
    "        pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "        self.pos_encoding = tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6435997-67ed-46fc-872f-b30f42a31cfb",
   "metadata": {},
   "source": [
    "잘 작동하는지 확인해 보자.\n",
    "\n",
    "- shape이 `(1, timestep, dim)`인 제로 시퀀스 입력에 대해 위치 정보를 부여하는 positional encoding이 잘 작동하는지 테스트\n",
    "\n",
    "- 아래 출력 결과를 보면, 출력이 timestep마다 다르며, 이는 positional encoding이 위치 정보를 명시적으로 부여했다는 의미 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fb5f22-a33e-40f3-bf37-f81fd6ef17f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 4), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
       "        [ 0.84147096,  0.5403023 ,  0.00999983,  0.99995   ],\n",
       "        [ 0.9092974 , -0.41614684,  0.01999867,  0.9998    ],\n",
       "        [ 0.14112   , -0.9899925 ,  0.0299955 ,  0.99955004],\n",
       "        [-0.7568025 , -0.6536436 ,  0.03998933,  0.9992001 ],\n",
       "        [-0.9589243 ,  0.2836622 ,  0.04997917,  0.99875027]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PositionalEncoding(timestep, dim)(np.zeros((1, timestep, dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e79979-b9af-4fdd-ac38-fbf389370e11",
   "metadata": {},
   "source": [
    "## Scaled dot-product attention\n",
    "\n",
    "Attention은 이전 단원에서 살펴본 것처럼 query, key, value들의 dot product들로 계산한다.\n",
    "\n",
    "Attention의 목적은 query와 key의 유사성을 dot-product로 계산하여, 이를 기반으로 value에 가중치를 부여하는 것이다.\n",
    "\n",
    "* **Query (Q)**: 현재 우리가 “관심 있는 항목”에 대한 표현. 디코더의 현재 시점 상태 등이 사용됨.\n",
    "  \n",
    "* **Key (K)**: 인코더의 각 위치에 대한 설명. 디코더가 어떤 인코더 위치에 주목할지 판단할 기준.\n",
    "  \n",
    "* **Value (V)**: 실제로 정보를 얻고자 하는 대상. 보통 Key와 동일한 위치에서 생성된 벡터.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a6b969-a478-48ed-958c-3dbd37b85b3d",
   "metadata": {},
   "source": [
    "### 가중치 행렬 연산\n",
    "\n",
    "Transformer의 Attention 메커니즘에서 Query, Key, Value는 각각 입력 시퀀스 `X_q`, `X_k`, `X_v`에 가중치 행렬 `W_q`, `W_k`, `W_v`를 곱하여 생성된다.\n",
    "\n",
    "- 만약 쿼리 입력 시퀀스 `X_q`와 키 입력 시퀀스 `X_k`가 같다면 self-attention이라고 부른다. \n",
    "\n",
    "- 쿼리 입력 시퀀스 `X_q`와 값 입력 시퀀스 `X_v`는 같을 수도 있고 다를 수도 있다.\n",
    "\n",
    "쿼리 입력 시퀀스의 차원을 `d_model_q`, 키 입력 시퀀스의 차원을 `d_model_q`이라고 하자. \n",
    "\n",
    "- 쿼리 입력 시퀀스의 shape : `(batch_size, seq_len_q, d_model_q)`\n",
    "\n",
    "- 키 입력 시퀀스의 shape : `(batch_size, seq_len_k, d_model_k)`\n",
    "\n",
    "가중치 행렬들의 shape은 다음과 같다.\n",
    "\n",
    "* `W_q`: `(d_model_q, key_dim)`  \n",
    "* `W_k`: `(d_model_k, key_dim)`  \n",
    "* `W_v`: `(d_model_q, val_dim)`  \n",
    "\n",
    "입력 시퀀스를 `X`들이라고 할 때, query, key, value의 계산 과정과 shape들은 다음과 같다.\n",
    "\n",
    "* `Q = X_q @ W_q`    # shape: `(batch_size, seq_len_q, key_dim)`\n",
    "* `K = X_k @ W_k`    # shape: `(batch_size, seq_len_k, key_dim)`\n",
    "* `V = X_v @ W_v`    # shape: `(batch_size, seq_len_k, val_dim)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825d5bb-9546-419d-a744-8a3220e3cb15",
   "metadata": {},
   "source": [
    "### 차원 관계 정리\n",
    "\n",
    "| 입력 `X`          | `W`                                | 쿼리, 키, 값 |\n",
    "| ------------- | --------------------------------- |-----------------|\n",
    "| `X_q` : `(batch_size, seq_len_q, d_model_q)` | `W_q` : `(d_model_q, key_dim)` | `Q` :  `(batch_size, seq_len_q, key_dim)`\n",
    "| `X_k` : `(batch_size, seq_len_k, d_model_k)` | `W_k`: `(d_model_k, key_dim)` | `K` : `(batch_size, seq_len_k, key_dim)`\n",
    "| `X_v` : `(batch_size, seq_len_k, d_model_v)` | `W_v`: `(d_model_q, val_dim)` | `V` : `(batch_size, seq_len_k, val_dim)`\n",
    "\n",
    "\n",
    "* `key_dim == query_dim`이어야 $\\mathrm{Q} \\, \\mathrm{K}^{\\top}$가 정의됨.\n",
    "  \n",
    "* `seq_len_k`와 `seq_len_q`는 시퀀스의 길이이며 같을 수도 있고, 다를 수도 있음. (ex: 인코더는 10, 디코더는 5)\n",
    "  \n",
    "* key의 dimension(`key_dim`)과 value의 dimension(`val_dim`)은 같을 수도 있고, 다를 수도 있음\n",
    "\n",
    "* `d_model_q`, `d_model_k`, `d_model_v` 또한 모두 같을 수도 있고 다를 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3706355-92eb-45eb-9d66-c30cf55cfb4b",
   "metadata": {},
   "source": [
    "### Attention 연산 요약\n",
    "\n",
    "1. 유사도 계산 (Dot Product)\n",
    "   - $\\text{scores} = \\mathrm{Q} \\, \\mathrm{K}^{\\top}, \\quad$ shape:  `(batch_size, seq_len_q, seq_len_k)` <br><br>\n",
    "\n",
    "2. Scaling (정규화)\n",
    "   - $\\text{scaled\\_scores} = \\frac{\\mathrm{Q} \\, \\mathrm{K}^{\\top}}{\\sqrt{\\text{key\\_dim}}}$ <br><br>\n",
    "\n",
    "3. Softmax로 확률 분포화 (각 query 시점 마다)\n",
    "   - $\\text{Attention Weights} = \\text{softmax}(\\text{scaled\\_scores})$ <br><br>\n",
    "\n",
    "4. Weighted sum of values \n",
    "   - $\\text{context} = \\text{Attention Weights} \\cdot \\mathrm{V}, \\quad $  shape: `(batch_size, seq_len_q, val_dim)`\n",
    "\n",
    "#### Scaling을 하는 이유\n",
    "\n",
    "- Dot product attention은 종종 `key_dim`(depth)의 제곱근으로 조정되는데, 이는 model의 depth가 클 경우 dot product의 값이 매우 커질 수 있기 때문이다. \n",
    "\n",
    "- 이렇게 되면 softmax function이 매우 좁은 범위에서 작동하게 되어, gradient가 작은 부분에서 매우 급격한 변화가 발생하는 'sharp' softmax가 생성될 수 있다.\n",
    "\n",
    "- 이러한 문제를 피하기 위해 depth의 제곱근으로 dot product 값을 나누어 조정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d26ee-51ca-4416-9dc4-d77f13b07fa5",
   "metadata": {},
   "source": [
    "아래 예제에서 `Q`, `K`, `V`는 `W`들과의 연산을 통해 이미 만들어진 query, key, value의 계산 결과라고 가정하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58700937-6949-4e51-9a0b-a352fb4aa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "Q = np.array([[0, 0, 10],\n",
    "                   [0, 10, 0],\n",
    "                   [10, 10, 0]])  # (seq_len_q, key_dim) = (3, 3)\n",
    "\n",
    "K = np.array([[10, 0, 0],\n",
    "                   [0, 10, 0],\n",
    "                   [0, 0, 10],\n",
    "                   [0, 0, 10]])  # (seq_len_k, key_dim) = (4, 3)\n",
    "\n",
    "V = np.array([[1, 0],\n",
    "                   [10, 0],\n",
    "                   [100, 5],\n",
    "                   [1000, 6]])  # (seq_len_k, val_dim) = (4, 2)\n",
    "\n",
    "key_dim = np.shape(K)[-1] # 3\n",
    "query_dim = np.shape(Q)[-1] # 3\n",
    "\n",
    "seq_len_q = np.shape(Q)[-2]  # 3\n",
    "seq_len_k = np.shape(K)[-2]  # 4\n",
    "seq_len_v = np.shape(V)[-2]  # 4\n",
    "\n",
    "\n",
    "matmul_qk = Q @ K.T   # attention score, (seq_len_q, seq_len_k) = (3, 4)\n",
    "\n",
    "scaled_attention_logits = matmul_qk / math.sqrt(key_dim) # scaled attention score\n",
    "\n",
    "attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (seq_len_q, seq_len_k) = (3, 4)\n",
    "\n",
    "output = tf.matmul(attention_weights, V)  # (seq_len_q, depth_v) = (3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557e824-9b1e-46fb-8e6c-d450cb1d6ffe",
   "metadata": {},
   "source": [
    "아래 코드에서 `attention_weights`을 프린트한 결과를 보면, 주어진 query가 value의 어디에 집중해야 하는지 설명한다.\n",
    "\n",
    "- Query `temp_q`의 첫번째 값은 value의 세번째와 네번째 값에 집중해야 한다.\n",
    "- Query `temp_q`의 두번째 값은 value의 두번째 값에 집중해야 한다.\n",
    "- Query `temp_q`의 세번째 값은 value의 첫번째와 두번째 값에 집중해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "75e80ba4-c9e0-498b-af8a-5c6ad4450ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weight : \n",
      " tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention weight : \\n\", attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583b705-e8c5-4f90-9700-bdfb2c7f4481",
   "metadata": {},
   "source": [
    "Attention weight를 value에 적용된 결과는 다음과 같다.\n",
    "\n",
    "- Query `Q`의 첫번째 값의 의미는 `[550.    5.5]`으로 해석됨.\n",
    "- Query `Q`의 두번째 값의 의미는 `[ 10.    0. ]`으로 해석됨.\n",
    "- Query `Q`의 세번째 값의 의미는 `[  5.5   0. ]`으로 해석됨.\n",
    "\n",
    "Output의 sequence 길이는 `seq_len_q`와 같고, dimension은 `dim_v`와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ddd3da9f-3e58-4eb4-9918-31fd2ddb88e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  : \n",
      " tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Output  : \\n\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c577e-46d3-4abc-a058-c8e2939a8395",
   "metadata": {},
   "source": [
    "## Multi-head attention\n",
    "\n",
    "**Multi-Head Attention**에서는 \n",
    "\n",
    "* 쿼리 Q, 키 K, 값 V의 차원을 `num_heads`개의 subspace로 분할하고, 각 head마다 독립적인 attention을 수행한 뒤,\n",
    "\n",
    "* 그 결과들을 **결합(concatenate)** 후 다시 선형 변환하여 하나의 출력으로 만든다.\n",
    "\n",
    "각, head별 쿼리와 키의 차원을 `key_dim`이라 하자.\n",
    "\n",
    "그러면 `key_dim * num_head`는 `Q` 전체의 feature 차원의 개수가 된다. \n",
    "\n",
    "예를 들어, `Q` 전체의 feature 차원이 `512`, `num_heads = 8`이면, 각 head에서 키와 쿼리는 `512 / 8 = 64`차원짜리 feature를 갖게 되는 셈."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "28133048-f344-41d1-bfd9-5f734d2569b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.25       0.25       0.25       0.25      ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  [0.5        0.5        0.         0.        ]]\n",
      "\n",
      " [[0.         0.33333333 0.33333333 0.33333333]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]]], shape=(2, 3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "Q = np.array([[0, 0, 10, 10],\n",
    "                   [0, 10, 0, 0],\n",
    "                   [10, 10, 0, 0]])  # (4, 3)\n",
    "\n",
    "K = np.array([[10, 0, 0, 0],\n",
    "                   [0, 10, 0, 10],\n",
    "                   [0, 0, 10, 0],\n",
    "                   [0, 0, 10, 0]])  # (4, 4)\n",
    "\n",
    "V = np.array([[1, 0],\n",
    "                   [10, 0],\n",
    "                   [100, 5],\n",
    "                   [1000, 6]])  # (4, 2)\n",
    "\n",
    "\n",
    "total_key_dim = np.shape(K)[-1] # 4\n",
    "total_v_dim = np.shape(V)[-1] # 2\n",
    "num_heads = 2\n",
    "\n",
    "key_dim = total_key_dim// num_heads\n",
    "v_dim = total_v_dim // num_heads\n",
    "\n",
    "Q = np.reshape(Q, (-1, num_heads, key_dim)) # shape = (seq_len, num_heads, key_dim)\n",
    "Q = Q.transpose((1, 0, 2)) # shape = (num_heads, seq_len, key_dim)\n",
    "\n",
    "K = np.reshape(K, (-1, num_heads, key_dim))\n",
    "K = K.transpose((1, 0, 2))\n",
    "\n",
    "V = np.reshape(V, (-1, num_heads, v_dim))\n",
    "V = V.transpose((1, 0, 2))\n",
    "\n",
    "matmul_qk = np.matmul(Q, K.transpose((0, 2, 1)))   # attention score\n",
    "\n",
    "scaled_attention_logits = matmul_qk / math.sqrt(key_dim) # scaled attention score, (..., seq_len_q, seq_len_k)\n",
    "\n",
    "attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "print(attention_weights)  # num_heads 개의 attention_weights들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e92a56-8480-48d1-985e-229adc3f9289",
   "metadata": {},
   "source": [
    "최종 output, 즉, 쿼리 별 value 결과값은 이전과 마찬가지로 `(seq_len_q, dim_v)`의 shape을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1814d7fc-5741-441f-96cf-3015ad02c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[277.75      ]\n",
      "  [ 10.        ]\n",
      "  [  5.5       ]]\n",
      "\n",
      " [[  3.66666667]\n",
      "  [  2.75      ]\n",
      "  [  2.75      ]]], shape=(2, 3, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "output = tf.matmul(attention_weights, V)  \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1b951165-5137-4912-bd18-8f69a0522e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[277.75         3.66666667]\n",
      " [ 10.           2.75      ]\n",
      " [  5.5          2.75      ]]\n"
     ]
    }
   ],
   "source": [
    "output = np.transpose(output, (1, 0, 2))  # (seq_len_q, num_heads, v_dim)\n",
    "output = np.reshape(output, (-1, total_v_dim))  # (seq_len_q, total_v_dim)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8066d2-2153-4069-87c5-fc20127f3f31",
   "metadata": {},
   "source": [
    "## Multi-Head Self Attention\n",
    "\n",
    "Transformer의 Multi-Head Self Attention의 작동 방식은 다음과 같다.\n",
    "\n",
    "- 이전에 공부한 어텐션 메커니즘에서는 query가 디코더에서 제공되고, key와 value는 인코더에서 제공된다. 이는 디코더가 인코더의 출력과 상호작용하여 관련 정보를 추출하는 방식.\n",
    "\n",
    "- **셀프** 어텐션에서는 query, key, value를 모두 동일한 입력 시퀀스에서 생성한다. 즉, 인코더 입력 데이터 자체에서 query, key, value를 추출함.\n",
    "\n",
    "- 이 방식은 입력 시퀀스의 각 요소가 시퀀스 내의 다른 모든 요소와 상호작용하여, 자신의 문맥(context)을 이해하도록 도와준다.\n",
    "\n",
    "- **Multi-Head** attention은 이러한 셀프 어텐션을 여러 헤드로 병렬 처리하여, 서로 다른 서브스페이스의 정보를 학습할 수 있게 한다. 각 헤드는 입력 데이터의 다른 부분에 초점을 맞추어 보다 풍부한 표현을 학습하는 효과가 있다.\n",
    "\n",
    "- 이를 통해 모델은 시퀀스 내의 긴 의존성을 효과적으로 캡처할 수 있으며, 자연어 처리와 같은 분야에서 문맥을 이해하는 데 매우 유용하다.\n",
    "\n",
    "- Self-attentions에서는 자연스럽게 `X_q = X_k`, `Q = K`이 된다. 단, value는 key와 다르게 지정 가능\n",
    "\n",
    "케라스에서는 [`tensorflow.keras.MultiHeadAttention`](https://keras.io/api/layers/attention_layers/multi_head_attention/)를 이용하여 구현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599afdf5-1013-44df-ae0b-2ebde66448a1",
   "metadata": {},
   "source": [
    "### MultiHeadAttention 구조\n",
    "\n",
    "`MultiHeadAttention`에서의 작업 흐름은 다음과 같다.\n",
    "\n",
    "```\n",
    "Input Tensor → [Dense Layer for Query (W_q)] → Queries (Q)\n",
    "Input Tensor → [Dense Layer for Key (W_k)]   → Keys (K)\n",
    "Input Tensor → [Dense Layer for Value (W_v)] → Values (V)\n",
    "\n",
    "[Split into h heads]  (Q → Q₁...Q_h,  K → K₁...K_h,  V → V₁...V_h)\n",
    "\n",
    "[For each attention head]                                                                      \n",
    "     [Scaled Dot Product Attention] (Q_i · K_i^T / sqrt(depth)) → Attention Scores\n",
    "        → [Softmax] → Attention Weights\n",
    "        → [Dot Product] (Attention Weights, V_i)\n",
    "        → Attention Outputs (for each head)\n",
    "               ↓                       \n",
    "[Concatenate Heads] → Combined all Head Outputs → [Dense Layer] →  Output\n",
    "\n",
    "```\n",
    "\n",
    "Self multi head attention 결과는 입력 시퀀스의 복잡한 관계를 학습하여, 시퀀스 내의 문맥 정보를 풍부하게 표현한 결과라고 볼 수 있다.\n",
    "\n",
    "`MultiHeadAttention`의 주요 인자는 다음과 같다.\n",
    "\n",
    "- `num_heads` : 병렬 처리되는 head들의 수.  head는 input dimension을 나누어서 사용하기 때문에, 일반적으로 input dimension이 head의 수로 나누어떨어지도록 설정된다.\n",
    "  \n",
    "- `key_dim` : 각 head 별 query 및 key의 벡터 차원, 전체 query 및 key 벡터는 `num_heads * key_dim`의 차원을 가짐\n",
    "\n",
    "`MultiHeadAttention`의 call argument로서 `query`, `key`, `value`가 존재하는데, 이들은 각각 Q, K, V를 생성하는데 사용되는 입력 벡터 역할을 한다고 생각하면 된다.\n",
    "\n",
    "- 즉, $W$들이 곱해지기 전의 값.\n",
    "\n",
    "- 마지막 Dense layer는 Concatenate된 head의 결과를 모델의 기대하는 차원으로 투영하는 역할. Timedistrbuted로 처리 됨.\n",
    "\n",
    "  - `output_shape`을 따로 지정할 수도 있고, default로 `output_shape = None`일 경우 (쿼리) 입력 차원과 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d9c11-6d06-40a5-8cb8-134364dae59d",
   "metadata": {},
   "source": [
    "### `MultiHeadAttention` 파라미터 분석\n",
    "\n",
    "간단하게 `key_dim = value_dim`이고, `output_shape`을 따로 설정하지 않은 상황, 즉, `output_dim = input_dim`에서 살펴보자.  \n",
    "\n",
    "- Q, K, V의 weight matrix들\n",
    "\n",
    "  - Q, K, V는 기본적으로 `input_dim` 차원의 벡터를 `num_heads * key_dim` 차원으로 보내는 역할\n",
    "  \n",
    "  - 각각 `(input_dim, num_heads * key_dim)` 크기의 행렬, 즉 각각 `input_dim * num_heads * key_dim`의 파라미터 수를 가짐.\n",
    "\n",
    "- Bias term for Q, K, V: 각각 `num_heads * key_dim` 개수의 bias term이 있음\n",
    "\n",
    "- Output projection dense layer 가중치 :\n",
    "\n",
    "  - Head output을 모두 concat한 후, 최종 출력 차원으로 다시 투영하는 dense layer : `(num_heads * value_dim) → output_dim`\n",
    "  \n",
    "    - 단, 아래 예제에서는 `key_dim = value_dim`을 가정 중  <br><br>\n",
    "  - W: shape = (`num_heads * key_dim`, `output_dim`), 보통 `output_dim = input_dim`\n",
    "\n",
    "  - bias : `output_dim`개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd22c2aa-7704-4aad-9e2d-707bebf2ba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 6, 24)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_47 (Multi  (None, 6, 24)       2400        ['input_19[0][0]',               \n",
      " HeadAttention)                                                   'input_19[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,400\n",
      "Trainable params: 2,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 이 값들을 변경해 가며 테스트해 보자.\n",
    "input_dim = 24\n",
    "key_dim = 3\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(timestep, input_dim))\n",
    "MHA_layer = layers.MultiHeadAttention(key_dim=key_dim, num_heads=num_heads)\n",
    "x = MHA_layer(encoder_inputs, encoder_inputs) # (query, value). key는 생략, 즉, key=query로 자동 설정\n",
    "model = keras.Model(encoder_inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "751aa207-5355-4683-8b0a-cc2df9de3faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q, K, V 계산을 위한 W와 bias들 파라미터의 수\n",
    "3 * (input_dim * num_heads * key_dim + num_heads * key_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03b28572-3edd-402e-b5bb-53d49c6b3666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마지막 dense layer의 파라미터 수. output_dim = input_dim\n",
    "num_heads * key_dim * input_dim +  input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a50a2094-2097-4549-bfd6-f188e7760c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총합\n",
    "3 * (input_dim * num_heads * key_dim + num_heads * key_dim) + num_heads * key_dim * input_dim +  input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a5931-c43b-4dbd-81dc-bf3f9cc71d38",
   "metadata": {},
   "source": [
    "물론 `key_dim != value_dim`과 `input_dim != output_dim`인 경우도 파라미터 개수를 계산해 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467256e4-8321-4031-8f17-3352177b700e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m value_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m      9\u001b[0m num_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m---> 11\u001b[0m encoder_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(timestep, input_dim))\n\u001b[0;32m     12\u001b[0m MHA_layer \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMultiHeadAttention(key_dim\u001b[38;5;241m=\u001b[39mkey_dim, value_dim\u001b[38;5;241m=\u001b[39mvalue_dim, num_heads\u001b[38;5;241m=\u001b[39mnum_heads, output_shape\u001b[38;5;241m=\u001b[39moutput_shape)\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m MHA_layer(encoder_inputs, encoder_inputs)  \u001b[38;5;66;03m# (query, value). key는 생략, 즉, key=query로 자동 설정\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# 이 값들을 변경해 가며 테스트해 보자.\n",
    "timestep = 6\n",
    "dim = 4\n",
    "\n",
    "input_dim = 24\n",
    "output_shape = 32  # output_dim\n",
    "key_dim = 3\n",
    "value_dim = 4\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(timestep, input_dim))\n",
    "MHA_layer = layers.MultiHeadAttention(key_dim=key_dim, value_dim=value_dim, num_heads=num_heads, output_shape=output_shape)\n",
    "x = MHA_layer(encoder_inputs, encoder_inputs)  # (query, value). key는 생략, 즉, key=query로 자동 설정\n",
    "model = keras.Model(encoder_inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eda6b48b-9460-4123-ba01-104b13429666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3056"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 수 계산\n",
    "# W_q, W_k, W_v와 bias들\n",
    "pa = 2 * (input_dim * num_heads * key_dim + num_heads * key_dim) + (input_dim * num_heads * value_dim + num_heads * value_dim) \n",
    "# dense layer\n",
    "pd = num_heads * value_dim * output_shape +  output_shape\n",
    "pa + pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93989123-cbf8-4368-a18d-a5be283d1acf",
   "metadata": {},
   "source": [
    "### 간단 예제\n",
    "\n",
    "입력 시퀀스의 각 time step 벡터를 self-attention으로 처리하여, 그 결과를 그대로 예측하는 간단한 예제를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d967e421-b3f8-4973-a826-47b0e00e0cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 5, 12)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_58 (Multi  (None, 5, 12)       624         ['input_25[0][0]',               \n",
      " HeadAttention)                                                   'input_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5, 12)        156         ['multi_head_attention_58[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 780\n",
      "Trainable params: 780\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "seq_len = 5\n",
    "d_model = 12\n",
    "num_heads = 4\n",
    "key_dim = d_model // num_heads\n",
    "batch_size = 32\n",
    "\n",
    "# 입력 데이터: 랜덤 시퀀스\n",
    "X = np.random.randn(1000, seq_len, d_model).astype(np.float32)\n",
    "Y = X.copy()  # 목표는 그대로 복사\n",
    "\n",
    "# 모델 구성\n",
    "inputs = tf.keras.Input(shape=(seq_len, d_model))\n",
    "\n",
    "# MHA Layer\n",
    "attention_out = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(inputs, inputs)\n",
    "\n",
    "# Optional: Dense layer (identity map)\n",
    "outputs = layers.Dense(d_model)(attention_out)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "285e5736-a7cb-42e1-b3f8-f30489ef96af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.0152 - val_loss: 0.9589\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.9713 - val_loss: 0.9206\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.9252 - val_loss: 0.8689\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8608 - val_loss: 0.7962\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7787 - val_loss: 0.7129\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6942 - val_loss: 0.6332\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.5577\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5436 - val_loss: 0.4883\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.4331\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.3858\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.3441\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.3113\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3123 - val_loss: 0.2900\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.2711\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2708 - val_loss: 0.2487\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2452 - val_loss: 0.2241\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2226 - val_loss: 0.2074\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2101 - val_loss: 0.1992\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2026 - val_loss: 0.1930\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1956 - val_loss: 0.1868\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1879 - val_loss: 0.1789\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1774 - val_loss: 0.1677\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1622 - val_loss: 0.1507\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1329\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1241\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1205\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1217 - val_loss: 0.1181\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1165\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.1151\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.1141\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1128\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1120\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1133 - val_loss: 0.1113\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.1107\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1099\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1114 - val_loss: 0.1091\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1087\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.1086\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.1081\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1078\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.1076\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.1074\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1083 - val_loss: 0.1070\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.1070\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.1069\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1067\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 0.1067\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1071 - val_loss: 0.1064\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1069 - val_loss: 0.1062\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.1061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f88303c10>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "model.fit(X, Y, epochs=100, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cdc8476c-5336-4b37-bdd7-b249f822525e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "Input:\n",
      "[[ 0.91  0.24  0.86 -0.19  0.68 -1.18  1.04  0.91  1.53 -1.74 -1.01  1.02]\n",
      " [ 0.66  0.68 -1.55 -1.5  -1.19  1.11  1.51 -0.91  0.5   0.7   0.69 -0.53]\n",
      " [-1.44  0.87 -0.28  0.02 -1.45  0.9  -0.04  0.54 -0.25  0.85  0.4  -1.49]\n",
      " [ 0.46  0.59  0.55  1.17 -1.2  -0.3  -1.07  2.08  0.42 -0.79 -0.45  0.51]\n",
      " [-0.15 -1.64 -0.12 -0.34 -0.86 -1.34  0.64  1.53 -0.92  0.39 -0.64  0.44]]\n",
      "Prediction:\n",
      "[[ 1.29  0.38  0.64 -0.15  0.58 -0.96  1.01  1.02  1.47 -1.43 -1.    0.49]\n",
      " [ 0.38  0.58 -1.34 -1.4  -1.25  0.77  1.28 -0.72  0.4   0.54  0.45 -0.56]\n",
      " [-1.48  0.43 -0.72 -0.06 -1.76  0.77  0.24  0.25 -0.76  0.41  0.17 -1.25]\n",
      " [ 0.31  0.65  0.27  0.91 -1.25 -0.37 -0.8   2.07  0.39 -0.48  0.06  0.44]\n",
      " [-0.03 -1.08 -0.   -0.08 -1.08 -1.5   0.3   1.8  -0.38  0.61 -0.05  0.52]]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.random.randn(1, seq_len, d_model).astype(np.float32)\n",
    "pred = model.predict(test_input)\n",
    "\n",
    "print(\"Input:\")\n",
    "print(np.round(test_input[0], 2))\n",
    "\n",
    "print(\"Prediction:\")\n",
    "print(np.round(pred[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadb9615-9cb2-4101-a34a-a2e1f581b7ec",
   "metadata": {},
   "source": [
    "## 인코더\n",
    "\n",
    "인코더 모델을 구성하는 함수를 정의하자. \n",
    "\n",
    "인코더 모델은 self-attetion 부분과 feed-forward 부분으로 구성된다.\n",
    "\n",
    "- 앞에서 공부한 인코더-디코더 모델에서 순환 신경망 대신 self-attention이 있는 형태\n",
    "\n",
    "Feed-forward 부분은 self-attention 메커니즘 이후에 입력 데이터에 대한 추가적인 비선형 변환을 수행하는 단계이다.\n",
    "\n",
    "이는 모델이 더 복잡하고 다양한 패턴을 학습할 수 있도록 도와준다. \n",
    "\n",
    "Transformer encoder의 feed-forward 부분은 일반적으로 두 개의 Dense 레이어와 활성화 함수로 구성된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4038d99-8b12-4b6e-80c4-8adba03d1273",
   "metadata": {},
   "source": [
    "\n",
    "### 인코더의 주요 구성\n",
    "\n",
    "Transformer의 인코더는 하나의 블록 안에 다음과 같은 주요 구성요소를 갖는다.\n",
    "\n",
    "1. Multi-Head Self-Attention Layer\n",
    "\n",
    "   * Transformer는 문장을 처리하기 위해 개발된 것으로, self-attention은 입력 시퀀스 내에서 단어들 간의 상호관계를 학습\n",
    "   * 같은 시퀀스 안에서 query, key, value가 동일하기 때문에 self-attention이라고 부름 <br><br>\n",
    "\n",
    "2. Layer Normalization\n",
    "   * 각 샘플의 각 time step 별로 해당 feature 차원(`axis=-1`)에 대해 평균과 분산을 계산하여 정규화하는 과정 → 학습 안정화, 수렴 향상\n",
    "   * Transformer에서는 Residual 연결 이후 또는 이전에 항상 LayerNormalization을 적용 <br><br>\n",
    "\n",
    "3. Residual connection : attention ouput + input\n",
    "   * Attention의 결과에 original 입력을 더해주는 과정을 residual connection이라고 부른다.\n",
    "   * `inputs`까지 직접적인 경로(identity path)를 만들어서, 역전파 시 gradient가 입력까지 잘 전달되게 함\n",
    "   * 완전히 새로 생성된 출력을 쓰기보단 기존 정보 + 조정된 정보로 자연스럽게 업데이트 <br><br>\n",
    "\n",
    "4. Position-wise Feed-Forward Network (FFN)\n",
    "\n",
    "   * 각 위치의 출력 벡터를 독립적으로 변환\n",
    "   * 일반적으로 `Dense → ReLU → Dropout → Dense` \n",
    "   * 보통 첫 번째 dense layer에서 차원이 확장되고, 두 번째 dense layer에서 원래 차원으로 복원 <br><br>\n",
    "\n",
    "5. 마지막으로 Residual connection 한 번 더 수행\n",
    "   * 역전파 시 Gradient 흐름을 원활하게 함\n",
    "   * 초기엔 FFN이 거의 학습되지 않아도 residual은 그대로 전달하여 정보 손실 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8638fe-dac6-46a1-acc2-fd5e5b831687",
   "metadata": {},
   "source": [
    "아래 인코더 모델의 텐서 흐름은 다음과 같다.\n",
    "\n",
    "```\n",
    "Input → [Layer Normalization] → [Multi-Head Attention] → [Dropout] → self-attention result\n",
    "    ↓      \n",
    "→ [Sum](Input + self-attention result) → <Residual>\n",
    "\n",
    "→ [Layer Normalization] → [Dense (ReLU)] → [Dropout] → [Dense] → Feedforward result  \n",
    "                                          \n",
    "→ [Sum](<Residual> + Feedforward result) → Encoder output\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096d1068-f6e7-48d9-a977-f559cba3f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 모델 구성\n",
    "def transformer_encoder(inputs, num_heads, key_dim, ff_dim, dropout=0.1):\n",
    "    # === Self-Attention Block ===\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    MHA_layer = layers.MultiHeadAttention(key_dim=key_dim, num_heads=num_heads, dropout=dropout)\n",
    "    \n",
    "    x = MHA_layer(query=x, value=x, key=x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "     # === Feed-Forward Block ===\n",
    "    ff = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    ff = layers.Dense(units=ff_dim, activation=\"relu\")(ff)  # ff_dim으로 확장\n",
    "    ff = layers.Dropout(dropout)(ff)\n",
    "    ff = layers.Dense(units=inputs.shape[-1])(ff) # 원래 차원으로 복원\n",
    "    return ff + res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff0e10-8b8b-4308-8bfc-079bd89f7ba7",
   "metadata": {},
   "source": [
    "적절한 input tensor를 생성하여 `transformer_encoder`에 입력하면 output tensor를 얻게 되어 추후에 모델을 생성할 때 이용할 수 있다.\n",
    "\n",
    "예를 들어, 다음과 같은 코드를 보라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c9a49dd-1010-4218-95ef-c3edcc7bacf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 4) dtype=float32 (created by layer 'tf.__operators__.add_2')>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs = keras.Input(shape=(timestep, dim))\n",
    "\n",
    "encoder_ouputs = transformer_encoder(encoder_inputs, num_heads = 2, key_dim = 8, ff_dim = 10, dropout = 0.1)\n",
    "encoder_ouputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ed119-845d-4c7a-b072-ca3d60bde68c",
   "metadata": {},
   "source": [
    "## 디코더\n",
    "\n",
    "디코더는 인코더와 비슷하나, 어텐션이 다음 세 단계에 걸쳐 이루어 진다.\n",
    "\n",
    "- **Masked self attention**\n",
    "  - 디코더가 순차적으로 값을 생성할 때 현재까지 생성된 값들만을 이용하여 attention을 수행한다.\n",
    "  - 즉, 미래에 디코더가 생성할 값은 attention 계산에 사용하지 않겠다는 의미이다.<br><br>\n",
    "    \n",
    "- Encoder-Decoder attention\n",
    "  - 디코더 출력과 인코더 출력 간의 attention   \n",
    "  - 디코더가 특정 시점 값을 생성할 때 인코더 출력 전체를 살펴보므로 masked attention은 아니다. <br><br>\n",
    " \n",
    "- Position-wise Feedforward Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71880d0-63f7-4710-a72f-16d808a75450",
   "metadata": {},
   "source": [
    "### Mask 행렬\n",
    "\n",
    "마스크 행렬은 어디를 가릴지 위치를 나태내 주는 행렬.\n",
    "\n",
    "- 가려야 할 위치가 1이고, 나머지는 0.\n",
    "- 가장 기본적으로 upper triangular part가 1이고 나머지는 0인 형태가 새용됨\n",
    "\n",
    "Transformer에서 attention mask는 `softmax`에 들어가기 전 score 행렬 `QKᵀ`에 다음과 같이 적용된다.\n",
    "\n",
    "$$\n",
    "\\text{Attention}(\\mathbf{Q}, \\mathbf K, \\mathbf V) = \\text{softmax} \\left( \\frac{\\mathbf Q \\mathbf{K}^\\top}{\\sqrt{d_k}} +  \\text{mask} \\cdot(-\\infty )\\right) \\mathbf{V}\n",
    "$$\n",
    "\n",
    "- 즉, softmax를 적용했을 때, 0이 되게 하기 위함\n",
    "  \n",
    "- 실제로는 $-\\infty$를 곱할 수 없기 때문에, `-1e9`와 같은 매우 작은 수를 곱함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1030d8c-c471-4c6c-8560-4036d962dcaa",
   "metadata": {},
   "source": [
    "Mask 행렬을 위해 다음 함수를 정의하자.\n",
    "\n",
    "여기서 `size`는 `timestep`에 해당 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee48567-8b85-43e7-9f75-3de7c2e68086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[0., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    # band_part(A, -1, 0)은 lower triangular 행렬을 추출\n",
    "    return 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "create_look_ahead_mask(timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97750681-7476-4f25-8209-23122104f5f6",
   "metadata": {},
   "source": [
    "활용 시에는 아래와 같이 인자로 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "907cf60f-f466-49fc-9c37-6bebb1206207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 4), dtype=float32, numpy=\n",
       "array([[[-0.35285255,  0.19823988, -0.07430167, -0.16018784],\n",
       "        [-0.46918437,  0.2635975 , -0.09879816, -0.21300009],\n",
       "        [-0.07339857,  0.04123684, -0.01545585, -0.03332144],\n",
       "        [-0.3841221 ,  0.21580775, -0.08088623, -0.17438357],\n",
       "        [-1.1912293 ,  0.66925734, -0.25084224, -0.5407937 ],\n",
       "        [-0.08105704,  0.04553952, -0.01706853, -0.03679824]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.random.randn(1, 3, 4)\n",
    "x = np.concatenate([temp, temp], axis = 1)\n",
    "\n",
    "layers.MultiHeadAttention(num_heads=1, key_dim=1)(query=x, value=x, attention_mask=create_look_ahead_mask(timestep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221548d-8e10-40fc-9479-bbaef24c3a66",
   "metadata": {},
   "source": [
    "아래 디코더 모델의 텐서 흐름은 다음과 같다.\n",
    "\n",
    "```\n",
    "Decoder Input  → [Layer Normalization] → [Masked Self Multi-Head Attention] → [Dropout] → self-attention result\n",
    "    ↓\n",
    "→ [Sum](Decoder Input + self-attention result) → <Residual1>\n",
    "                                                                 \n",
    "Encoder Output → [Encoder-Decoder Multi-Head Attention with Encoder Output] → [Dropout] → Encoder-Decoder attention result\n",
    "\n",
    "→ [Sum](<Residual1> + Encoder-Decoder attention result) → <Residual2>\n",
    "        \n",
    "→ [Layer Normalization] → [Dense (ReLU)] → [Dropout] → [Dense] → Feedforward result  \n",
    "                                          \n",
    "→ [Sum](<Residual2> + Feedforward result) → Decoder output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79098ae4-7f9d-4a98-a059-73d395f90247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 디코더 블록\n",
    "def transformer_decoder(inputs, encoder_output, num_heads, key_dim, ff_dim, dropout=0.1):\n",
    "    seq_len = tf.shape(inputs)[1]\n",
    "    look_ahead_mask = create_look_ahead_mask(seq_len)\n",
    "\n",
    "    # Masked Multi-Head Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    MHA_layer1 = layers.MultiHeadAttention(key_dim=key_dim, num_heads=num_heads, dropout=dropout)\n",
    "    x = MHA_layer1(query=x, value=x, key=x, attention_mask=look_ahead_mask)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Encoder-Decoder Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    MHA_layer2 = layers.MultiHeadAttention(key_dim=key_dim, num_heads=num_heads, dropout=dropout)\n",
    "    x = MHA_layer2(query=x, value=encoder_output, key=encoder_output)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + res\n",
    "\n",
    "    # Feed Forward Part\n",
    "    ff = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    ff = layers.Dense(units=ff_dim, activation=\"relu\")(ff)\n",
    "    ff = layers.Dropout(dropout)(ff)\n",
    "    ff = layers.Dense(units=inputs.shape[-1])(ff)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b05eeb-0882-4b76-ae06-10fd6940eb9c",
   "metadata": {},
   "source": [
    "## Transformer 모델 구성\n",
    "\n",
    "위에서 정의된 인코더 디코더를 이용하여 transformer 모형을 구성해 보겠다.\n",
    "\n",
    "`build_transformer_model` 함수 내에서 반복문을 이용하여 encoder와 decoder를 여러 블록으로 설정할 수 있다.\n",
    "\n",
    "- 각 블록은 입력 데이터에 대한 더 복잡한 패턴과 관계를 학습할 수 있도록 도와주고,\n",
    "- 깊은 구조는 멀리 떨어진 토큰 간의 복잡한 관계도 포착한다고 알려져 있다.\n",
    "\n",
    "전체 모델 구조는 다음과 같이 간단히 나타낼 수 있다. \n",
    "    \n",
    "```\n",
    "[Encoder Input] ─► PositionalEncoding ─► [Encoder Blocks] ─► encoder_outputs\n",
    "                                                                  ↓\n",
    "[Decoder Input] ─► PositionalEncoding ─► [Decoder Blocks using encoder_outputs] ─► Final Dense Layer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6df34e47-1e62-46f1-b12a-ed7c69ea54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer_model(input_shape, key_dim, num_heads, ff_dim, num_encoder_blocks, num_decoder_blocks, dropout=0.1):\n",
    "    encoder_inputs = keras.Input(shape=input_shape)\n",
    "    x = PositionalEncoding(input_shape[0], input_shape[1])(encoder_inputs)\n",
    "    for _ in range(num_encoder_blocks):\n",
    "        x = transformer_encoder(x, key_dim, num_heads, ff_dim, dropout)\n",
    "    encoder_outputs = x\n",
    "\n",
    "    #decoder_inputs = keras.Input(shape=(input_shape[0] + 1, input_shape[1]))\n",
    "    decoder_inputs = keras.Input(shape=(None, input_shape[1]))\n",
    "    x = PositionalEncoding(input_shape[0] + 1, input_shape[1])(decoder_inputs)\n",
    "    for _ in range(num_decoder_blocks):\n",
    "        x = transformer_decoder(x, encoder_outputs, key_dim, num_heads, ff_dim, dropout)\n",
    "\n",
    "    outputs = layers.Dense(input_shape[1], activation=\"linear\")(x)\n",
    "    return keras.Model([encoder_inputs, decoder_inputs], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11976e30-1124-4587-a58e-2c0e3c9649e3",
   "metadata": {},
   "source": [
    "간단한 트랜스포머 모델을 구현하여 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9297069b-a42f-4930-b5d5-d72d89b69ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 6, 12)]      0           []                               \n",
      "                                                                                                  \n",
      " positional_encoding_8 (Positio  (None, 6, 12)       0           ['input_9[0][0]']                \n",
      " nalEncoding)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 6, 12)       24          ['positional_encoding_8[0][0]']  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 6, 12)       624         ['layer_normalization_25[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_25[0][0]', \n",
      "                                                                  'layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 6, 12)        0           ['multi_head_attention_15[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 6, 12)       0           ['dropout_25[0][0]',             \n",
      " ambda)                                                           'positional_encoding_8[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 6, 12)       24          ['tf.__operators__.add_25[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 6, 64)        832         ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 6, 64)        0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, None, 12)]   0           []                               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 6, 12)        780         ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " positional_encoding_9 (Positio  (None, None, 12)    0           ['input_10[0][0]']               \n",
      " nalEncoding)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 6, 12)       0           ['dense_25[0][0]',               \n",
      " ambda)                                                           'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_5 (TFOpLamb  (3,)                0           ['positional_encoding_9[0][0]']  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 6, 12)       24          ['tf.__operators__.add_26[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  ()                  0           ['tf.compat.v1.shape_5[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 6, 12)       624         ['layer_normalization_27[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_27[0][0]', \n",
      "                                                                  'layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " tf.ones_5 (TFOpLambda)         (None, None)         0           ['tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 6, 12)        0           ['multi_head_attention_16[0][0]']\n",
      "                                                                                                  \n",
      " tf.linalg.band_part_5 (TFOpLam  (None, None)        0           ['tf.ones_5[0][0]']              \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 6, 12)       0           ['dropout_27[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, None, 12)    24          ['positional_encoding_9[0][0]']  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLambda  (None, None)        0           ['tf.linalg.band_part_5[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 6, 12)       24          ['tf.__operators__.add_27[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, None, 12)    624         ['layer_normalization_29[0][0]', \n",
      " HeadAttention)                                                   'tf.math.subtract_5[0][0]',     \n",
      "                                                                  'layer_normalization_29[0][0]', \n",
      "                                                                  'layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 6, 64)        832         ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, None, 12)     0           ['multi_head_attention_17[0][0]']\n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 6, 64)        0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, None, 12)    0           ['dropout_29[0][0]',             \n",
      " ambda)                                                           'positional_encoding_9[0][0]']  \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 6, 12)        780         ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, None, 12)    24          ['tf.__operators__.add_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 6, 12)       0           ['dense_27[0][0]',               \n",
      " ambda)                                                           'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, None, 12)    624         ['layer_normalization_30[0][0]', \n",
      " HeadAttention)                                                   'tf.__operators__.add_28[0][0]',\n",
      "                                                                  'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, None, 12)     0           ['multi_head_attention_18[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, None, 12)    0           ['dropout_30[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, None, 12)    0           ['dropout_30[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_6 (TFOpLamb  (3,)                0           ['tf.__operators__.add_31[0][0]']\n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  ()                  0           ['tf.compat.v1.shape_6[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.ones_6 (TFOpLambda)         (None, None)         0           ['tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_6 (TFOpLam  (None, None)        0           ['tf.ones_6[0][0]']              \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, None, 12)    24          ['tf.__operators__.add_31[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.subtract_6 (TFOpLambda  (None, None)        0           ['tf.linalg.band_part_6[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, None, 12)    624         ['layer_normalization_32[0][0]', \n",
      " HeadAttention)                                                   'tf.math.subtract_6[0][0]',     \n",
      "                                                                  'layer_normalization_32[0][0]', \n",
      "                                                                  'layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, None, 12)     0           ['multi_head_attention_19[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, None, 12)    0           ['dropout_32[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_31[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, None, 12)    24          ['tf.__operators__.add_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, None, 12)    624         ['layer_normalization_33[0][0]', \n",
      " HeadAttention)                                                   'tf.__operators__.add_28[0][0]',\n",
      "                                                                  'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, None, 12)     0           ['multi_head_attention_20[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, None, 12)    0           ['dropout_33[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, None, 12)    0           ['dropout_33[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, None, 12)     156         ['tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,316\n",
      "Trainable params: 7,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 하이퍼파라미터\n",
    "timestep = 6\n",
    "dim = 12\n",
    "num_heads = 4\n",
    "key_dim = dim // num_heads\n",
    "\n",
    "ff_dim = 64\n",
    "num_encoder_blocks = 2\n",
    "num_decoder_blocks = 2\n",
    "dropout = 0.1\n",
    "\n",
    "input_shape = (timestep, dim)\n",
    "model = build_transformer_model(input_shape, key_dim, num_heads, ff_dim, num_encoder_blocks, num_decoder_blocks, dropout)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6592dccf-d8b0-47da-8b35-76d2ac943f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f464d52c-56f2-4a36-be85-5edfccfad9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 3s 12ms/step - loss: 1.3577\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.8764\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.7679\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.7136\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.6731\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6419\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6193\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5947\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5703\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5471\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5234\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.5053\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4893\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4750\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4677\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4617\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4536\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4598\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4541\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4485\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4534\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4503\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4474\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4437\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4446\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4401\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4395\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4409\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4422\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4393\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4398\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4377\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4388\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4350\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4379\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4381\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4348\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4365\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4319\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4356\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4333\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4305\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4295\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4281\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4262\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4267\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4233\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4202\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4201\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4215\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4227\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4217\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4248\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4225\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4217\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4228\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4196\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4173\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4180\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4145\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4124\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.4116\n",
      "Epoch 63/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4179\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4127\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4149\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4086\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4113\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4112\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4078\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4138\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4171\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4118\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4080\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4086\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4071\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4107\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4101\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4110\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4126\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4142\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4126\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4099\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4049\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4105\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4052\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4058\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4027\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4046\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4087\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4028\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.4043\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4077\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4041\n",
      "Epoch 94/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4041\n",
      "Epoch 95/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.4020\n",
      "Epoch 96/100\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.3991\n",
      "Epoch 97/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4025\n",
      "Epoch 98/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4025\n",
      "Epoch 99/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4048\n",
      "Epoch 100/100\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.4087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1457dbd9c90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 데이터: 랜덤 시퀀스\n",
    "num_samples = 5000\n",
    "input_sequences = np.random.randn(num_samples, timestep, dim).astype(np.float32)\n",
    "token = np.zeros((num_samples, 1, dim), dtype=np.float32)\n",
    "decoder_input_sequences = np.concatenate([token, input_sequences], axis=1)\n",
    "target_sequences = np.concatenate([input_sequences, token], axis=1)\n",
    "\n",
    "# 학습\n",
    "model.fit(\n",
    "    [input_sequences, decoder_input_sequences],\n",
    "    target_sequences,\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06379ea2-394a-48a4-a36f-e1dd3065a5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_4\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 6, 12) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, timestep, dim)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 2\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(test_input[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filef51y3w42.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_4\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 6, 12) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.random.randn(1, timestep, dim).astype(np.float32)\n",
    "pred = model.predict(test_input)\n",
    "\n",
    "print(\"Input:\")\n",
    "print(np.round(test_input[0], 2))\n",
    "\n",
    "print(\"Prediction:\")\n",
    "print(np.round(pred[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a23c8f18-ccad-4fc4-aa9e-bbbdea5b3704",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "test_input = np.random.randn(1, timestep, dim).astype(np.float32)\n",
    "decoder_input = np.zeros((1, 1, dim), dtype=np.float32)\n",
    "\n",
    "for t in range(timestep):\n",
    "    out = model.predict([test_input, decoder_input], verbose=0)\n",
    "    next_token = out[:, t:t+1, :]  # 현재 t 위치의 출력\n",
    "    predicted.append(next_token)\n",
    "    decoder_input = np.concatenate([decoder_input, next_token], axis=1)\n",
    "\n",
    "predicted_seq = np.concatenate(predicted, axis=1)  # [1, T, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ec85ee2-e0f0-45c5-a480-fb670f607fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.56281745, -0.8456227 , -0.05178611, -0.16327456,\n",
       "          1.2374431 ,  1.1965969 , -0.62234485,  0.3076654 ,\n",
       "          1.1524637 , -0.73824143,  2.00496   , -0.16286363],\n",
       "        [-0.88927627, -1.780127  , -2.0132275 ,  0.21154052,\n",
       "          0.4425037 , -0.88579226, -1.4644228 ,  2.1800575 ,\n",
       "         -0.2141665 ,  1.640988  ,  0.43723208, -1.0082473 ],\n",
       "        [ 1.5016494 , -1.3054186 ,  0.72994304,  1.5310088 ,\n",
       "         -0.6996465 ,  0.56920165,  1.0108896 , -0.52887356,\n",
       "          2.1680448 , -0.71544194,  0.8011044 ,  2.6808014 ],\n",
       "        [-0.15406431,  0.05326122,  1.4059649 ,  0.9655612 ,\n",
       "         -1.1902698 ,  0.3355811 ,  0.8155559 , -0.02471921,\n",
       "          1.0535312 , -0.2982765 , -0.82076645, -0.3680453 ],\n",
       "        [-0.70112187,  1.2849799 , -0.20613562,  1.1740515 ,\n",
       "         -0.47708115, -0.5688111 , -3.0328202 ,  0.09202323,\n",
       "          0.0791605 , -1.4008986 ,  2.2237077 ,  0.23005815],\n",
       "        [-0.3937977 ,  0.1334683 , -0.06983052, -0.5179708 ,\n",
       "         -0.87245715,  1.5290926 ,  0.33927363, -0.8376999 ,\n",
       "         -2.00893   ,  1.9720898 , -0.18279305, -0.02055051]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0c11f54-71c9-4822-8282-744d3f6d57a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.05215218, -0.32099086,  0.05171119,  0.5466317 ,\n",
       "         -0.04191903,  0.49736896,  0.08567269, -0.05788277,\n",
       "          0.28991142,  0.03397844,  0.3085669 ,  0.3925903 ],\n",
       "        [-0.04915009, -0.5552441 ,  0.05699911,  0.51846075,\n",
       "          0.05707505,  0.4113412 ,  0.14855969, -0.08813046,\n",
       "          0.2595783 , -0.01290401,  0.18506548,  0.33023116],\n",
       "        [ 0.43015164, -0.7938588 ,  0.5410278 ,  0.76707137,\n",
       "          0.30434287,  0.71674883,  0.55201447, -0.24343239,\n",
       "          0.44754186,  0.13251553,  0.2805745 ,  0.49243137],\n",
       "        [ 0.7127412 , -0.72990894,  0.50376666,  0.8911247 ,\n",
       "          0.41628164,  0.5649649 ,  0.48907593, -0.24030338,\n",
       "          0.4830096 ,  0.09156   ,  0.46128464,  0.59547985],\n",
       "        [ 0.57836103, -0.5342305 ,  0.41435134,  0.7855849 ,\n",
       "          0.3832935 ,  0.39343297,  0.3513914 , -0.2521879 ,\n",
       "          0.3547135 ,  0.01559202,  0.4694244 ,  0.48669627],\n",
       "        [ 0.27676368, -0.6367852 ,  0.47276357,  0.6164756 ,\n",
       "          0.24396579,  0.7251063 ,  0.44626012, -0.14971212,\n",
       "          0.42630252,  0.13905512,  0.15646139,  0.52919906]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78167bb3-834f-4065-80c8-0448d865104c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfa871e1-7389-41c0-8c84-24a0ec88c8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.502808  97.714516  97.88251   94.13253  ]\n",
      " [89.997986  25.810356  51.15441   59.639    ]\n",
      " [61.727127  91.25      53.523922  13.2438965]\n",
      " [66.58228   91.26392   74.37523   62.950336 ]\n",
      " [ 5.8382034 26.999859  80.668434  67.09706  ]\n",
      " [83.33164   21.120419  16.811142  72.92662  ]]\n",
      "[[83.33164   21.120419  16.811142  72.92662  ]\n",
      " [ 5.8382034 26.999859  80.668434  67.09706  ]\n",
      " [66.58228   91.26392   74.37523   62.950336 ]\n",
      " [61.727127  91.25      53.523922  13.2438965]\n",
      " [89.997986  25.810356  51.15441   59.639    ]\n",
      " [22.502808  97.714516  97.88251   94.13253  ]\n",
      " [ 0.         0.         0.         0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 생성\n",
    "num_samples = 10000\n",
    "input_sequences = np.random.uniform(0, 100, size=(num_samples, timestep, dim)).astype(np.float32)\n",
    "timesteps_indices = np.arange(1, timestep + 1)  # [1, 2, 3, ..., timesteps]\n",
    "\n",
    "reversed_sequences = np.flip(input_sequences, axis=1)\n",
    "\n",
    "token = np.zeros((num_samples, 1, dim), dtype=np.float32)\n",
    "decoder_input_sequences = np.concatenate([token, reversed_sequences], axis=1)\n",
    "target_sequences = np.concatenate([reversed_sequences, token], axis=1)\n",
    "\n",
    "print(input_sequences[0,:,:])\n",
    "print(target_sequences[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "048e3d62-56c3-4802-9907-d5939ca7d7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 73s 117ms/step - loss: 11767.6729\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 3346.7405\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 2373.7576\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 36s 117ms/step - loss: 1892.4965\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 1643.2819\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 35s 110ms/step - loss: 1535.1670\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 1323.7083\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 1230.7706\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 1160.4109\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 1116.9185\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 1087.0846\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 1080.5458\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 1060.9156\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 1058.2856\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 1122.8456\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 1052.0750\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1034.0240\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1035.5385\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 1035.2379\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 1017.2198\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1021.8309\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 1007.6244\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 1002.1792\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 993.1469\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 990.8380\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 989.3334\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 992.8408\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 994.4470\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 1020.5122\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 1018.0886\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 1009.3083\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 35s 110ms/step - loss: 1005.9750\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 1003.8496\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 1002.2148\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 1001.7905\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 1000.6813\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 999.3827\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 996.0180\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 994.7081\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 992.7259\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 988.3064\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 985.5159\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 985.8983\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 984.5076\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 984.3174\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 982.1414\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 983.4413\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 986.6089\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 36s 113ms/step - loss: 984.8574\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 982.7164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25dc2206380>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(\n",
    "    [input_sequences, decoder_input_sequences],\n",
    "    target_sequences,\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72848adc-4c82-47fc-bc4f-d23f2c8180bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 1 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 7, 4), found shape=(None, 1, 4)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, dim), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(timestep):\n\u001b[1;32m----> 6\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m out[:, t:t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# 현재 t 위치의 출력\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     predicted\u001b[38;5;241m.\u001b[39mappend(next_token)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filef51y3w42.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 1 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 7, 4), found shape=(None, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "test_input = np.random.uniform(0, 100, size=(1, timestep, dim)).astype(np.float32)\n",
    "decoder_input = np.zeros((1, 1, dim), dtype=np.float32)\n",
    "\n",
    "for t in range(timestep):\n",
    "    out = model.predict([test_input, decoder_input], verbose=0)\n",
    "    next_token = out[:, t:t+1, :]  # 현재 t 위치의 출력\n",
    "    predicted.append(next_token)\n",
    "    decoder_input = np.concatenate([decoder_input, next_token], axis=1)\n",
    "\n",
    "predicted_seq = np.concatenate(predicted, axis=1)  # [1, T, D]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b7c23-b5a3-4be3-9014-e3116fea64a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19620afe-ce2b-49a2-ab92-45d6588ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_sine_data(n_samples=1000, timesteps=50):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for _ in range(n_samples):\n",
    "        freq = np.random.uniform(1, 3)\n",
    "        amp = np.random.uniform(0.5, 1.5)\n",
    "        x = np.linspace(0, 2 * np.pi, timesteps)\n",
    "        sine = amp * np.sin(freq * x)\n",
    "        if np.random.rand() < 0.5:\n",
    "            Y.append(0)\n",
    "            X.append(sine)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "            sine[np.random.randint(10, 30):np.random.randint(30, 50)] = 0.0\n",
    "            X.append(sine)\n",
    "    X = np.array(X)[..., np.newaxis]\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = generate_sine_data()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a1ffd61-7189-4e48-afb4-92b0a28ddb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sample_waves(X, Y, n=5):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.plot(X[i].squeeze(), label=f\"Class {Y[i]}\")\n",
    "        plt.ylim(-2, 2)\n",
    "        plt.title(f\"Label: {Y[i]}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 앞에서 생성한 데이터 시각화\n",
    "plot_sample_waves(X, Y, n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1eb49c9-aca7-4fea-adce-a9c8e810426d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 51, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_decoder_input_and_target(X):\n",
    "    \"\"\"\n",
    "    X: (num_samples, timesteps, d_model)\n",
    "    returns:\n",
    "        decoder_input: (num_samples, timesteps + 1, d_model)\n",
    "        target:        (num_samples, timesteps + 1, d_model)\n",
    "    \"\"\"\n",
    "    d_model = X.shape[2]\n",
    "    batch_size = X.shape[0]\n",
    "    timesteps = X.shape[1]\n",
    "\n",
    "    # decoder_input: [0 vector] + X → shape: (batch, timesteps + 1, d_model)\n",
    "    start_token = np.zeros((batch_size, 1, d_model), dtype=np.float32)\n",
    "    decoder_input = np.concatenate([start_token, X], axis=1)\n",
    "\n",
    "    # target: X + [0 vector] → shape: (batch, timesteps + 1, d_model)\n",
    "    end_token = np.zeros((batch_size, 1, d_model), dtype=np.float32)\n",
    "    target = np.concatenate([X, end_token], axis=1)\n",
    "\n",
    "    return decoder_input, target\n",
    "\n",
    "decoder_input_train, target_train = create_decoder_input_and_target(X_train)\n",
    "decoder_input_test, target_test = create_decoder_input_and_target(X_test)\n",
    "decoder_input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac89613-25cf-465b-a78d-e51331ad9cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 50, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " positional_encoding_5 (Positio  (None, 50, 1)       0           ['input_5[0][0]']                \n",
      " nalEncoding)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_70 (LayerN  (None, 50, 1)       2           ['positional_encoding_5[0][0]']  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_40 (Multi  (None, 50, 1)       113         ['layer_normalization_70[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_70[0][0]', \n",
      "                                                                  'layer_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_70 (Dropout)           (None, 50, 1)        0           ['multi_head_attention_40[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 50, 1)       0           ['dropout_70[0][0]',             \n",
      " ambda)                                                           'positional_encoding_5[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_71 (LayerN  (None, 50, 1)       2           ['tf.__operators__.add_70[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 50, 64)       128         ['layer_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 50, 64)       0           ['dense_61[0][0]']               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 51, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 50, 1)        65          ['dropout_71[0][0]']             \n",
      "                                                                                                  \n",
      " positional_encoding_6 (Positio  (None, 51, 1)       0           ['input_6[0][0]']                \n",
      " nalEncoding)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 50, 1)       0           ['dense_62[0][0]',               \n",
      " ambda)                                                           'tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_11 (TFOpLam  (3,)                0           ['positional_encoding_6[0][0]']  \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " layer_normalization_72 (LayerN  (None, 50, 1)       2           ['tf.__operators__.add_71[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_11 (S  ()                  0           ['tf.compat.v1.shape_11[0][0]']  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " multi_head_attention_41 (Multi  (None, 50, 1)       113         ['layer_normalization_72[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_72[0][0]', \n",
      "                                                                  'layer_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " tf.ones_10 (TFOpLambda)        (51, 51)             0           ['tf.__operators__.getitem_11[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 50, 1)        0           ['multi_head_attention_41[0][0]']\n",
      "                                                                                                  \n",
      " tf.linalg.band_part_10 (TFOpLa  (51, 51)            0           ['tf.ones_10[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_72 (TFOpL  (None, 50, 1)       0           ['dropout_72[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_71[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_74 (LayerN  (None, 51, 1)       2           ['positional_encoding_6[0][0]']  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.subtract_10 (TFOpLambd  (51, 51)            0           ['tf.linalg.band_part_10[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " layer_normalization_73 (LayerN  (None, 50, 1)       2           ['tf.__operators__.add_72[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_42 (Multi  (None, 51, 1)       113         ['layer_normalization_74[0][0]', \n",
      " HeadAttention)                                                   'tf.math.subtract_10[0][0]',    \n",
      "                                                                  'layer_normalization_74[0][0]', \n",
      "                                                                  'layer_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 50, 64)       128         ['layer_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 51, 1)        0           ['multi_head_attention_42[0][0]']\n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 50, 64)       0           ['dense_63[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_74 (TFOpL  (None, 51, 1)       0           ['dropout_74[0][0]',             \n",
      " ambda)                                                           'positional_encoding_6[0][0]']  \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 50, 1)        65          ['dropout_73[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_75 (LayerN  (None, 51, 1)       2           ['tf.__operators__.add_74[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_73 (TFOpL  (None, 50, 1)       0           ['dense_64[0][0]',               \n",
      " ambda)                                                           'tf.__operators__.add_72[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_43 (Multi  (None, 51, 1)       113         ['layer_normalization_75[0][0]', \n",
      " HeadAttention)                                                   'tf.__operators__.add_73[0][0]',\n",
      "                                                                  'tf.__operators__.add_73[0][0]']\n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 51, 1)        0           ['multi_head_attention_43[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_75 (TFOpL  (None, 51, 1)       0           ['dropout_75[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_74[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_76 (TFOpL  (None, 51, 1)       0           ['dropout_75[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_75[0][0]']\n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 51, 1)        2           ['tf.__operators__.add_76[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 852\n",
      "Trainable params: 852\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X.shape[1:]\n",
    "\n",
    "model = build_transformer_model(\n",
    "    input_shape=input_shape,\n",
    "    key_dim=8,\n",
    "    num_heads=2,\n",
    "    ff_dim=64,\n",
    "    num_encoder_blocks=2,\n",
    "    num_decoder_blocks=1,\n",
    "    dropout=0.1\n",
    ")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b389b3bd-0528-40f3-bbf7-ba640ddc44bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 8s 114ms/step - loss: 0.6901 - val_loss: 0.6602\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.6381 - val_loss: 0.6148\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.6005 - val_loss: 0.5820\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5708 - val_loss: 0.5557\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5451 - val_loss: 0.5324\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5240 - val_loss: 0.5115\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5036 - val_loss: 0.4920\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.4849 - val_loss: 0.4739\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.4668 - val_loss: 0.4568\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.4500 - val_loss: 0.4408\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.4342 - val_loss: 0.4257\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.4198 - val_loss: 0.4115\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.4054 - val_loss: 0.3983\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.3920 - val_loss: 0.3859\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.3797 - val_loss: 0.3743\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.3681 - val_loss: 0.3636\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.3577 - val_loss: 0.3536\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.3475 - val_loss: 0.3443\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.3387 - val_loss: 0.3357\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.3300 - val_loss: 0.3277\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.3217 - val_loss: 0.3204\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.3143 - val_loss: 0.3136\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.3076 - val_loss: 0.3074\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.3015 - val_loss: 0.3017\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.2956 - val_loss: 0.2965\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2902 - val_loss: 0.2918\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.2855 - val_loss: 0.2875\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.2812 - val_loss: 0.2836\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.2769 - val_loss: 0.2800\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.2733 - val_loss: 0.2769\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.2699 - val_loss: 0.2740\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.2668 - val_loss: 0.2715\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2645 - val_loss: 0.2692\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.2616 - val_loss: 0.2671\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2596 - val_loss: 0.2653\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.2575 - val_loss: 0.2637\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.2557 - val_loss: 0.2623\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.2541 - val_loss: 0.2611\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2526 - val_loss: 0.2599\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.2512 - val_loss: 0.2590\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.2502 - val_loss: 0.2582\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.2491 - val_loss: 0.2575\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2483 - val_loss: 0.2568\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.2474 - val_loss: 0.2563\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2466 - val_loss: 0.2559\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.2460 - val_loss: 0.2555\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.2459 - val_loss: 0.2552\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.2452 - val_loss: 0.2550\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.2449 - val_loss: 0.2548\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2446 - val_loss: 0.2546\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.2442 - val_loss: 0.2545\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2440 - val_loss: 0.2544\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.2440 - val_loss: 0.2543\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2436 - val_loss: 0.2542\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.2434 - val_loss: 0.2542\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2435 - val_loss: 0.2542\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2434 - val_loss: 0.2542\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2430 - val_loss: 0.2541\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2430 - val_loss: 0.2542\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.2428 - val_loss: 0.2542\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2429 - val_loss: 0.2542\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.2430 - val_loss: 0.2542\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2429 - val_loss: 0.2542\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2429 - val_loss: 0.2542\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2428 - val_loss: 0.2543\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.2426 - val_loss: 0.2543\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.2427 - val_loss: 0.2543\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.2427 - val_loss: 0.2543\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.2426 - val_loss: 0.2543\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2426 - val_loss: 0.2543\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.2428 - val_loss: 0.2544\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.2426 - val_loss: 0.2544\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.2426 - val_loss: 0.2544\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.2425 - val_loss: 0.2544\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.2426 - val_loss: 0.2545\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.2427 - val_loss: 0.2545\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 3s 149ms/step - loss: 0.2425 - val_loss: 0.2545\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.2428 - val_loss: 0.2545\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.2426 - val_loss: 0.2545\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.2429 - val_loss: 0.2545\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.2425 - val_loss: 0.2545\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.2423 - val_loss: 0.2545\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.2427 - val_loss: 0.2545\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 3s 149ms/step - loss: 0.2426 - val_loss: 0.2545\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.2425 - val_loss: 0.2545\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2426 - val_loss: 0.2545\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2427 - val_loss: 0.2546\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.2424 - val_loss: 0.2546\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.2426 - val_loss: 0.2546\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.2427 - val_loss: 0.2546\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.2426 - val_loss: 0.2546\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.2427 - val_loss: 0.2546\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.2426 - val_loss: 0.2546\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.2427 - val_loss: 0.2546\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2424 - val_loss: 0.2546\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.2427 - val_loss: 0.2546\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.2426 - val_loss: 0.2546\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.2424 - val_loss: 0.2546\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.2426 - val_loss: 0.2546\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.2428 - val_loss: 0.2546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25dc1e05960>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X_train, decoder_input_train],\n",
    "    target_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a372864-d298-4309-bc11-80d817b129fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 32ms/step - loss: 0.5745\n",
      "Test accuracy: 0.5744931697845459\n"
     ]
    }
   ],
   "source": [
    "eval_result = model.evaluate([X_test, decoder_input_test], Y_test)\n",
    "print(\"Test accuracy:\", eval_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6d9e3-f04e-4e36-a954-4d9a102ea3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
