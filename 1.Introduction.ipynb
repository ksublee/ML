{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계적 학습 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 대용량 데이터로부터 패턴을 찾아내는 알고리즘과 이를 성취하기 위해 활용되는 컴퓨팅 기술을 일컫는다.\n",
    "\n",
    "컴퓨터가 데이터를 순차적으로 학습하면서 성능이 향상되는 과정을 거치기 때문에 머신러닝이라는 이름이 붙었다.\n",
    "\n",
    "인공지능 분야에서 학습된 모형을 이용해 예측하거나 분류하는 역할을 수행하며, 인공지능의 방법론 중 주요한 축으로 활약하고 있다.\n",
    "\n",
    "전통적 통계적 방법론의 연장선 상에서 통계적 기계학습 혹은 통계적 학습이라고도 하며, 두 용어를 구분해서 사용하기도 하고 혼용하여 사용하기도 한다.\n",
    "\n",
    "전통적인 통계학에서 추론을 중요히 여겼다면, 머신러닝에서는 예측을 중요시한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 예제\n",
    "\n",
    "다음 각각의 그림은 Sales에 대한 TV, Radio, Newspaper에 대한 선형회귀선이다.\n",
    "\n",
    "<img src=\"tv_radio_newspaper.png\" width=\"900\">\n",
    "\n",
    "Sales에 대한 보다 정확한 예측을 위해서는 어떤 변수를 고려해야 할까?\n",
    "\n",
    "TV? Radio? Newspaper? 아마 모두일 것이다.\n",
    "\n",
    "위 그림을 보고 다음의 예측 모형을 생각해 볼 수 있다.\n",
    "\n",
    "$$ \\mathrm{Sales} \\approx f(\\mathrm{TV}, \\mathrm{Radio}, \\mathrm{Newspaper}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표기법\n",
    "\n",
    "여기서 Sales는 반응 (response) 변수 혹은 예측에 대한 target이 된다. 보통 $Y$를 반응변수로 둔다.\n",
    "\n",
    "TV나 Radio 등은 feature, input, 혹은 predictor라고 한다. 차례로 $X_1, X_2, X_3$라고 하겠다.\n",
    "\n",
    "따라서 다음의 input vector를 만들 수 있다.\n",
    "\n",
    "$$ X = \\begin{pmatrix} X_1 \\\\ X_2 \\\\ X_3 \\end{pmatrix} $$\n",
    "\n",
    "그리고 우리의 예측모형은 다음과 같이 쓸 수 있다.\n",
    "\n",
    "$$ Y = f(X) + \\epsilon $$\n",
    "\n",
    "여기서 $\\epsilon$은 측정 에러이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f$가 예측을 잘 한다는 것은 새로운 $x$ 값에 대해 계산된 $Y$가 정확하다는 것을 의미한다.\n",
    "\n",
    "모형의 복잡도가 그리 높지 않다면 입력변수가 반응변수에 어떻게 영향을 미치는지 파악할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $f$는 어떻게 구하는가?\n",
    "\n",
    "아래의 상황에서 $f(X)$의 이상적인 값은 얼마일까? 예를 들어, $X=4$일 때, $f(X)$의 적절한 값은 무엇일까?\n",
    "\n",
    "<img src=\"E_y.png\" width=\"700\">\n",
    "\n",
    "수학적으로 다음과 같이 표현할 수 있다.\n",
    "\n",
    "$$ f(4) = \\mathbb E [Y | X=4] $$\n",
    "\n",
    "즉, $X=4$일 때 $Y$의 조건부 기댓값이다.\n",
    "\n",
    "$ f(x) = \\mathbb E [Y | X=x] $를 regression 함수라고 부른다.\n",
    "\n",
    "벡터 $X$에 대해서도 다음과 같이 확장할 수 있다.\n",
    "\n",
    "$$ f(x) = f(x_1, x_2, x_3) = \\mathbb E [Y | X_1 = x_1, X_2 = x_2, X_3 = x_3] $$\n",
    "\n",
    "또한, $f$는 mean-squared prediction error 관점에서 ideal 혹은 optimal predictor라고 불리우는데, 모든 함수 $g$에 대해 \n",
    "\n",
    "$$ f = \\min_{g}\\mathbb E[(Y - g(X))^2 | X = x]$$\n",
    "\n",
    "이기 때문이다.\n",
    "\n",
    "$ \\epsilon = Y - f(x) $는 irreducible 에러라고 하며, 우리가 $f$의 참값을 알더라도, $Y$의 랜덤성 때문에 발생하는 어쩔 수 없는 에러이다.\n",
    "\n",
    "$f$의 추정치인 $\\hat f$에 대해,\n",
    "\n",
    "$$ \\mathbb E [(Y - \\hat f(X))^2 | X = x ] = [f(x) - \\hat f (x)]^2 + \\mathrm{Var} (\\epsilon) $$\n",
    "\n",
    "이며, 이 중 $[f(x) - \\hat f (x)]^2$는 reducible한 부분이고, $\\mathrm{Var} (\\epsilon)$는 irreducible한 부분이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $f$를 어떻게 추정해야 할까?\n",
    "\n",
    "일반적으로 정확히 $X=4$에 해당하는 데이터의 수는 매우 적을 것이다.\n",
    "\n",
    "따라서, 정확한 $\\mathbb E[Y | X=x]$를 계산하기 힘들다.\n",
    "\n",
    "보다 완화된 버전을 이용하여,\n",
    "\n",
    "$$ \\hat f(x) = \\mathrm{Ave} ( Y | X \\in \\mathcal N (x) $$\n",
    "\n",
    "를 이용할 수 있다. 여기서 $\\mathcal N (x)$는 $x$의 적절한 neighborhood를 의미하며, 일종의 local average라고 볼 수 있다.\n",
    "\n",
    "입력 변수의 수 $p$가 적고 총 데이터의 수 $N$이 충분히 크다면 위 neighborhood 방법은 잘 적용된다.\n",
    "\n",
    "만약 $p$가 크다면 위 방법을 쉽게 적용할 수 없다. 이를 차원의 저주 (curse of dimensionality)라고 부른다.\n",
    "\n",
    "$\\mathrm{Ave} ( Y | X \\in \\mathcal N (x)$를 계산하기 위해, 예를 들어, 전체 데이터의 10%가 필요하자.\n",
    "\n",
    "만약, 차원이 적다면 큰 문제는 없겠지만, 차원이 커지면 10% neighborhood는 더 이상 local이 아니게 된다.\n",
    "\n",
    "즉, local averaging을 통해 $\\mathbb E [Y | X=x]$를 계산하고자 했던 취지를 만족하지 못한다.\n",
    "\n",
    "따라서, 단순 local averaging이 아닌, 다양한 통계적 학습 기법을 이용해야 할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric model\n",
    "\n",
    "선형모형은 parameteric model의 대표적인 예이다.\n",
    "\n",
    "$$ f_L (X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p $$\n",
    "\n",
    "간단한 선형모형은 비록 완벽히 맞는 일은 거의 없지만, $f$라는 true function에 대한 해석 가능한 근사치로 중요하게 사용된다.\n",
    "\n",
    "선형모형은 이차모형 등으로 확장할 수 있다.\n",
    "\n",
    "$$ f_Q (X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_1^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Income에 대한 다음의 적합된 모형들을 고려해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"L_income.png\" width=\"500\">\n",
    "\n",
    "위 그림은 빨간 점들은 시뮬레이션으로 생성된 값이며, 선형모형을 적합하였다.\n",
    "\n",
    "$$ \\hat f_L (\\mathrm{education}, \\mathrm{seniority}) = \\hat \\beta_0 + \\hat \\beta_1 \\times \\mathrm{education} + \\hat \\beta_2 \\times \\mathrm{seniority} $$\n",
    "\n",
    "빨간 점들과 평면 사이의 거리가 오차를 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"spline_income.png\" width=\"500\">\n",
    "\n",
    "위 그림에서는 같은 데이터에 대해, thin-plate spline이라는 보다 flexible한 방법을 적용하였다.\n",
    "\n",
    "앞의 선형모형과 비교하였을 때, 오차의 크기들이 줄어든 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"spline2_income.png\" width=\"500\">\n",
    "\n",
    "마지막으로 보다 더 flexible한 spline regression을 적용하였다. \n",
    "\n",
    "여기서는 적합된 모형이 아무런 오차를 발생하지 않는다.\n",
    "\n",
    "하지만, 중요한 점은 오차가 없다고 해서 이 모형이 좋은 모형이라는 것이 아니다.\n",
    "\n",
    "새로운 데이터를 테스트하면 아마도 큰 오차가 발생할 것이며, 이를 overfitting 되어 있다고 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trade-off\n",
    "\n",
    "예측 정확성 vs 해석 능력 (interpretability)\n",
    "\n",
    "* 선형 모형은 해석 능력이 좋지만, thin-plate spline은 해석 능력이 떨어진다.\n",
    "\n",
    "* 반면, thin-plate spline이 더 좋은 예측 정확성을 지닌다.\n",
    "\n",
    "Good fit vs over-fit or under-fit\n",
    "\n",
    "* 적절한 적합은 overfitting과 underfitting 사이에 위치한다. 그러면 정확히 어디쯤이 될 것인가?\n",
    "\n",
    "* 위 예제에서 선형모형은 underfitting, 세번째 모형은 overfitting이다.\n",
    "\n",
    "Parsimony vs black-box\n",
    "\n",
    "* 모형 간결성이 대체로 좋으나 보다 높은 성능을 위해 black-box predictor를 선택할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모형 정확성 평가\n",
    "\n",
    "훈련 데이터 (training data) $\\mathrm{Tr} = \\{x_i, y_i\\}_1^N $에 대한 어떤 모형 적합을 $\\hat f(x)$라고 하자.\n",
    "\n",
    "Average sqaured prediction error를 계산하여 모형의 정확성을 평가한다고 하자.\n",
    "\n",
    "$$ \\mathrm{MSE}_{\\mathrm{Tr}} = \\mathrm{Ave}_{i \\in \\mathrm{Tr}} [ y_i  - \\hat f(x_i)]^2 $$\n",
    "\n",
    "즉, $\\mathrm{MSE}_{\\mathrm{Tr}}$를 최소화하는 적합을 $\\hat f$라 하면, 이는 overfit을 할 가능성이 높다.\n",
    "\n",
    "이보다는 테스트 데이터 $\\mathrm{Te} = \\{x_i, y_i\\}_1^N $를 따로 선정하여 다음을 최소화하는 적합을 찾아야 한다.\n",
    "\n",
    "$$ \\mathrm{MSE}_{\\mathrm{Te}} = \\mathrm{Ave}_{i \\in \\mathrm{Te}} [ y_i  - \\hat f(x_i)]^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fitting_ex1.png\" width=\"800\">\n",
    "\n",
    "위 그림의 좌측에서 검은 선이 실제 $f$이다.\n",
    "\n",
    "점들은 $f$에 오차가 포함된 관찰값들이다.\n",
    "\n",
    "오렌지색, 파란색, 초록색 선들은 서로 다른 flexibility를 가지는 모형에 대한 적합 결과이다.\n",
    "\n",
    "오른쪽 그림의 빨간선은 모형의 flexibility에 따른 $\\mathrm{MSE}_{\\mathrm{Te}}$이고 회색선은 $\\mathrm{MSE}_{\\mathrm{Tr}}$에 대한 것이다.\n",
    "\n",
    "오른쪽 그림에서 파란색 네모가 가장 작은 $\\mathrm{MSE}_{\\mathrm{Te}}$를 가지며 가장 잘 적합된 모형을 의미한다.\n",
    "\n",
    "$\\mathrm{MSE}_{\\mathrm{Tr}}$는 결국 모형이 복잡할수록 작은 값을 가지는 경향이 있으며, $\\mathrm{MSE}_{\\mathrm{Tr}}$가 모형 평가에 이용되기 힘든 면을 보여준다.\n",
    "\n",
    "주확색 선형 모형은 underfitting을 초록색 복잡한 모형은 overfitting의 결과를 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fitting_ex2.png\" width=\"800\">\n",
    "\n",
    "두 번째 예제는 $f$의 참값이 직선에 가까운 경우이다.\n",
    "\n",
    "따라서, 선형 모형의 적합인 오렌지색 또한 매우 작은 $\\mathrm{MSE}_{\\mathrm{Te}}$를 가진다.\n",
    "\n",
    "초록색은 전형적인 overfitting의 모양을 보이며, 비록 작은 $\\mathrm{MSE}_{\\mathrm{Tr}}$를 가지더라도 높은 $\\mathrm{MSE}_{\\mathrm{Te}}$를 가져 적합에 사용되었던 훈련 데이터가 아닌 새로운 테스트 데이터에는 안 좋은 성능을 보임을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fitting_ex3.png\" width=\"800\">\n",
    "\n",
    "마지막으로 true $f$ 자체가 복잡한 함수의 예제이다.\n",
    "\n",
    "이 경우는 바로 전 예제와는 달리 선형 모형이 가장 큰 $\\mathrm{MSE}_{\\mathrm{Te}}$를 가지며 가장 안 좋은 성능을 보임을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Trade-off\n",
    "\n",
    "Fit model : $\\hat f(x)$  with training data $\\mathrm{Tr}$\n",
    "\n",
    "True model : $Y = f(X) + \\epsilon$\n",
    "\n",
    "테스트 관찰값 $(x_0, y_0)$에 대해 다음의 식이 성립한다.\n",
    "\n",
    "$$ \\mathbb E \\left( y_0 -  \\hat f (x_0) \\right)^2 = \\mathrm{Var}(\\hat f (x_0)) + [\\mathrm{Bias}(\\hat f(x_0))]^2 + \\textrm{Var}(\\epsilon)$$\n",
    "\n",
    "여기서 $\\textrm{Var}(\\hat f(x_0))$는 훈련 데이터 $\\mathrm{Tr}$가 바뀌었을 때 변화하는 $\\hat f$의 변동이다. $\\hat f$는 훈련 데이터에 의해 결정되므로 훈련 데이터가 바뀐다면 $\\hat f$도 변한다.\n",
    "\n",
    "$[\\mathrm{Bias}(\\hat f(x_0))]^2 = \\mathbb E[\\hat f(x_0)] - f(x_0)$로서 적합된 모형이 실제 모형과 다른 정도를 나타낸다.\n",
    "\n",
    "$\\mathrm{Var}(\\hat f (x_0))$와 $[\\mathrm{Bias}(\\hat f(x_0))]^2$의 관계를 Bias-Variance trade-off라고 한다.\n",
    "\n",
    "모형의 flexibility가 올라가면 $\\mathrm{Var}(\\hat f (x_0))$가 증가한다. 높은 복잡도의 모형에서는 훈련 데이터가 바뀌면 $\\hat f$도 크게 바뀔 것이다. 반면, 모형의 복잡도가 높으면 적합의 수준 또한 높으므로 $[\\mathrm{Bias}(\\hat f(x_0))]^2$는 감소한다.\n",
    "\n",
    "모형의 flexibility가 낮아지면 $[\\mathrm{Bias}(\\hat f(x_0))]^2$가 증가한다. 모형이 간단하면 데이터에 충분히 적합되어 있지 않을 수 있기 때문에 bias가 증가한다. 반면, 훈련 데이터가 바뀌어도 $\\hat f$가 크게 바뀌진 않을 것이다.\n",
    "\n",
    "전체 변동 $\\mathbb E \\left( y_0 -  \\hat f (x_0) \\right)^2$을 줄이려면, bias와 variance가 동시에 낮아지는 지점을 찾아야 한다.\n",
    "\n",
    "이는 통상적으로 테스트 에러를 가장 최소화하는 flexibility를 가지는 모형을 선택함으로서 이루어진다.\n",
    "\n",
    "과적합(overfitting) 모형에서는 $\\textrm{Var}(\\hat f(x_0))$가 높고, 과소적합(underfitting)된 모형에서는 $[\\mathrm{Bias}(\\hat f(x_0))]^2$가 높다.\n",
    "\n",
    "아래 그림은 위 예제들의 bias-variance 관계를 보여준다.\n",
    "\n",
    "<img src=\"bias_variance.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 (Classification) 문제\n",
    "\n",
    "지금까지는 regression 문제들에 대해 생각해 보았다. 이제 분류 문제를 생각해 보자.\n",
    "\n",
    "예를 들어, 이메일은 $\\mathcal C = (\\mathrm{spam}, \\mathrm{ham})$ 중의 하나로 구분할 수 있다.\n",
    "\n",
    "이처럼 반응변수 $Y$가 질적 변수일 때, 우리는 다음의 일들을 할 수 있다.\n",
    "\n",
    "* 분류기 (classifier) $\\mathcal C (X)$를 만들어 미래에 관찰되는 관찰값 $X$를 $\\mathcal C$ 중의 하나로 분류한다.\n",
    "\n",
    "* 분류 작업에 있어 불확실성을 평가한다.\n",
    "\n",
    "* 예측 변수인 $X=(X_1, \\cdots, X_p)$의 역할을 연구한다.\n",
    "\n",
    "이상적인 $\\mathcal C(X)$는 무엇일까?\n",
    "\n",
    "$\\mathcal C$에 $K$개의 원소가 있고, 이를 $1,2,\\cdots, K$라고 하자. 그리고\n",
    "\n",
    "$$ p_k(x) = \\mathbb P (Y=k | X=x), \\quad k=1, \\cdots, K$$\n",
    "\n",
    "라고 하면, 이를 $x$에서의 conditional class probability라고 할 수 있다.\n",
    "\n",
    "그러면 $x$에서의 Bayes optimal classifier는 다음과 같이 정의된다.\n",
    "\n",
    "$$ C(x) = j \\textrm{ if } p_j(x) = \\max \\{p_1(x), p_2(x), \\cdots, p_K(x) \\} $$\n",
    "\n",
    "<img src=\"classifier1.png\" width=\"800\">\n",
    "\n",
    "예를 들어, 위 그림에서 $x=5$일 때, $Y=0$일 조건부 확률, 즉, $p_0(5)$는 노란색으로, $p_1(5)$는 파란색으로 나타나 있다.\n",
    "\n",
    "따라서, Bayes optimal classifier에 따르면, $C(5) = 1$이다.\n",
    "\n",
    "그러면, $C$는 어떻게 추정하는가? 예전에 언급했던 nearest-neighbor averagin 방법을 사용해 볼 수 있겠다. 아래의 그림에서 빨간 점선이 가상의 neighnorhood를 나타낸다.\n",
    "\n",
    "<img src=\"classifier2.png\" width=\"800\">\n",
    "\n",
    "이전과 마찬가지로 차원이 증가하면, 이 방법은 어려워진다. 다만, 차원증가에 따른 추정의 어려움은 $\\hat p_k(x)$에서 보다는 $\\hat C(x)$에서 더 적다고 한다.\n",
    "\n",
    "$\\hat C(x)$의 성능 측정은 보통 다음의 에러 비율로 측정한다.\n",
    "\n",
    "$$ \\mathrm{Err}_{\\mathrm{Te}} = \\mathrm{Ave}_{i \\in \\mathrm{Te}} I [y_i \\neq \\hat C (x_i)] $$\n",
    "\n",
    "여기서 $I$는 characteristic function으로 $y_i \\neq \\hat C (x_i)$일 경우 1의 값을, 그 외에는 0의 값을 가진다.\n",
    "\n",
    "즉, 추정된 분류기 $\\hat C(x)$에 의한 분류가 잘못된 경우의 비율을 계산한다.\n",
    "\n",
    "앞에서 언급한, $p_k(x)$의 참값을 이용한 Bayes classifier가 가장 작은 에러를 가진다. 물론 현실에서는 true $p_k(x)$를 알긴 힘들다.\n",
    "\n",
    "앞으로 공부할 support vector machine은 $C(x)$를 어떻게 정할지 연구한다.\n",
    "\n",
    "Logistic regression이나 generalized additive 모형에서는 $p_k(x)$를 어떻게 정할지 연구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors\n",
    "\n",
    "앞서 설명했듯이, $p_k(x)$는 알지 못하기 때문에 현실에서 Bayes classifier를 이용하기는 힘들다.\n",
    "\n",
    "대신 $p_k(x)$의 추정치인 $\\hat p_k(x)$를 이용하여 분류하는 경우가 많다.\n",
    "\n",
    "그 중의 한 예는 K-nearest neighbors (KNN) 방법이다.\n",
    "\n",
    "KNN에서는 훈련 데이터 $x_0$의 근처 K개의 관찰값들을 neighbor인 $\\mathcal N_0$로 정한다.\n",
    "\n",
    "그리고, 클래스  $j$에 대한 조건부 확률을 $\\mathcal N_0$ 중 반응변수의 값이 $j$에 속하는 비율로 추정한다. 즉,\n",
    "\n",
    "$$ \\mathbb P(Y=j | X = x_0) = \\frac{1}{K} \\sum_{i \\in \\mathcal N_0} I (y_i = j) $$\n",
    "\n",
    "새로운 테스트 관찰값이 오면, 추정된 조건부 확률을 비교하여 가장 큰 값을 가지는 조건부 확률의 클래스가 새로운 테스트 관찰값의 클래스로 정해진다.\n",
    "\n",
    "KNN은 자연수 $K$의 값을 무엇으로 하는가에 따라 분류 방법이 달라진다.\n",
    "\n",
    "$K$가 작을수록 overfitting이 되고 $K$가 클수록 underfitting이 된다. 아래의 그림들을 보며 비교하자. 보라색 점선이 실제 경계선이다.\n",
    "\n",
    "<img src=\"KNN_1_100.png\" width=\"800\">\n",
    "\n",
    "가장 좋은 분류기의 $K$는 1과 100의 중간 어디에 위치할 것이다. \n",
    "\n",
    "<img src=\"KNN_10.png\" width=\"400\">\n",
    "\n",
    "다음 그림은 training error와 test error를 $1/K$의 그래프로 표현하였다.\n",
    "\n",
    "<img src=\"KNN_error.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬 표현법\n",
    "\n",
    "모형 모수가 $\\theta_1, \\cdots, \\theta_p$이고, $\\boldsymbol{\\theta} = \\begin{bmatrix}\\theta_0  & \\theta_1 &  \\cdots &  \\theta_p \\end{bmatrix}^{\\top} $는 모수 벡터이다. 여기서 ${}^\\top$는 전치 (transpose)를 나타낸다.\n",
    "\n",
    "일반적으로 $x_{ij}$를 $j$번째 입력변수의 $i$번째 관찰값으로 정의한다. 여기서 $i=1,2,\\cdots,N$이고 $j=1,\\cdots,p$이다.\n",
    "\n",
    "\n",
    "그러면 $x_{ij}$로 이루어진 $N \\times p$ 행렬 $\\mathbf{X}$를 생각할 수 있다.\n",
    "\n",
    "$$ \n",
    "\\mathbf{X} = \\begin{bmatrix} \n",
    "    x_{11} & x_{12} & \\cdots & x_{1p}\\\\\n",
    "    x_{21} & x_{22} & \\cdots & x_{2p}\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{N1} & x_{N2} & \\cdots & x_{Np}  \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$i$번째 관찰값들인 행들은 $x_i$로 표현한다. 즉, $x_i$는 총 $p$개의 값을 지니며,\n",
    "\n",
    "$$ x_i = \\begin{bmatrix} x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\ x_{ip}\\end{bmatrix} $$\n",
    "\n",
    "이다.\n",
    "\n",
    "$j$번째 입력변수의 모든 관찰값은 $\\mathrm{x}_j$로 표현한다. 즉, $\\mathrm{x}_j$는 총 $n$개의 값을 지니며,\n",
    "\n",
    "$$ \\mathbf{x}_j = \\begin{bmatrix} x_{1j} \\\\ x_{2j} \\\\ \\vdots \\\\ x_{Nj} \\end{bmatrix}$$\n",
    "\n",
    "이다.\n",
    "\n",
    "또한 반응변수들의 관찰값 또한 벡터로서 표현된다.\n",
    "\n",
    "$$ \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
